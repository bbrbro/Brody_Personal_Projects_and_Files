{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2be446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, GRU, LSTM, TimeDistributed,SimpleRNN, Flatten, Dense, Input, InputLayer, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, GlobalAvgPool2D, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7f77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time=np.linspace(0,1,n_steps)\n",
    "    series = 0.5 * np.sin((time-offsets1)*(freq1*10+10))\n",
    "    series+= 0.2 * np.sin((time-offsets2)*(freq2*20+20))\n",
    "    series+= 0.1 * (np.random.rand(batch_size, n_steps)-0.5)\n",
    "    \n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9441e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=50\n",
    "series = generate_time_series(10000, n_steps +1)\n",
    "xt, yt = series[:7000, :n_steps],series[:7000, -1]\n",
    "xv, yv = series[7000:9000, :n_steps],series[7000:9000, -1]\n",
    "xte, yte = series[9000:, :n_steps],series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "258e3ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020978257"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = xv[:,-1]\n",
    "#niave solution\n",
    "np.mean(keras.losses.mean_squared_error(yv, yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a330d36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 716us/step - loss: 0.0037 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003676652442663908, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Niave dense\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=[50,1]),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(xt, yt, epochs = 20, validation_data = (xv, yv),verbose=0)\n",
    "model.evaluate(xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e0d0484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002689632121473551"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mse\")\n",
    "history = model.fit(xt, yt, epochs = 20, validation_data = (xv, yv),verbose=0)\n",
    "model.evaluate(xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15729ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01271074265241623"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps=50\n",
    "series = generate_time_series(10000, n_steps +10)\n",
    "xt, yt = series[:7000, :n_steps],series[:7000, -10:,0]\n",
    "xv, yv = series[7000:9000, :n_steps],series[7000:9000,  -10:,0]\n",
    "xte, yte = series[9000:, :n_steps],series[9000:,  -10:,0]\n",
    "\n",
    "model = Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mse\")\n",
    "history = model.fit(xt, yt, epochs = 20, validation_data = (xv, yv),verbose=0)\n",
    "model.evaluate(xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15979e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function last_time_step_mse at 0x0000016D1AF59280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function last_time_step_mse at 0x0000016D1AF59280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1458 - last_time_step_mse: 0.1425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14582772552967072, 0.142517551779747]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps=50\n",
    "series = generate_time_series(10000, n_steps +10)\n",
    "Y = np.empty((10000,n_steps,10))\n",
    "for step in range(1,10+1):\n",
    "    Y[:,:,step-1] = series[:,step:step+n_steps,0]\n",
    "    \n",
    "Yt  = Y[:7000]\n",
    "Yv  = Y[7000:9000]\n",
    "Yte = Y[9000:]\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    SimpleRNN(20, return_sequences=True),\n",
    "    TimeDistributed(Dense(10))\n",
    "])\n",
    "\n",
    "def last_time_step_mse(Y,Yp):\n",
    "    return keras.metrics.mean_squared_error(Y[:,-1],Yp[:,-1])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss = \"mse\", optimizer = optimizer, metrics = [last_time_step_mse])\n",
    "history = model.fit(xt, Yt, epochs = 20, validation_data = (xv, Yv),verbose=0)\n",
    "model.evaluate(xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "737ab139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1458210051059723"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    LSTM(20, return_sequences=True),\n",
    "    TimeDistributed(Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mse\")\n",
    "history = model.fit(xt, Yt, epochs = 20, validation_data = (xv, Yv),verbose=0)\n",
    "model.evaluate(xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46fe2d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14595060050487518"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input((None,1)),\n",
    "    Conv1D(filters=20, kernel_size=4, strides=2, padding =\"valid\"),\n",
    "    GRU(20, return_sequences=True),\n",
    "    GRU(20, return_sequences=True),\n",
    "    TimeDistributed(Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mse\")\n",
    "history = model.fit(xt, Yt[:,3::2], epochs = 20, validation_data = (xv, Yv[:,3::2]),verbose=0)\n",
    "model.evaluate(xte, Yte[:,3::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cbdc226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1458 - last_time_step_mse: 0.1424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14582794904708862, 0.14241839945316315]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((None,1)))\n",
    "for rate in (1,2,4,8) * 2:\n",
    "    model.add(Conv1D(filters=20, kernel_size=2, padding =\"causal\", activation=\"relu\",dilation_rate=rate))  \n",
    "model.add(Conv1D(filters=10, kernel_size=1))\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = \"adam\", metrics =[last_time_step_mse])\n",
    "history = model.fit(xt, Yt, epochs = 20, validation_data = (xv, Yv),verbose=0)\n",
    "model.evaluate(xte, Yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbe416",
   "metadata": {},
   "source": [
    "**Natural Language Processing with RNNs and Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e443dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\",shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "883a4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([shakespeare_text])\n",
    "max_id = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6126beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "[encoded]=np.array(tokenizer.texts_to_sequences([shakespeare_text]))-1\n",
    "train_size = dataset_size*90//100\n",
    "dataset=tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b713e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=100\n",
    "window_length = n_steps +1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a31f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.flat_map(lambda window: window.batch(window_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0841c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000016D20E32280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000016D20E32280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset=dataset.map(lambda windows: (windows[:,:-1],windows[:,1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2a41bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51682e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, None, 39), (None, None)), types: (tf.float32, tf.int32)> 39\n"
     ]
    }
   ],
   "source": [
    "print(dataset, max_id)\n",
    "model = Sequential([\n",
    "    GRU(128, return_sequences=True, input_shape=[None, max_id], dropout = 0.2, recurrent_dropout=0.2),\n",
    "    GRU(128, return_sequences=True, dropout = 0.2, recurrent_dropout=0.2),\n",
    "    TimeDistributed(Dense(max_id, activation =\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6069690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c259e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6816/4169994272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3_64\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \u001b[1;31m# Run validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'logs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df734bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a400c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d652ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
