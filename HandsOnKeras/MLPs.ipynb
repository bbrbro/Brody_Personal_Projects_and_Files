{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building an image classifier using the sequential API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X, y), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation, X_train = X[50000:]/255, X[:50000]/255\n",
    "y_validation, y_train = y[50000:], y[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=[28,28]))\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "             optimizer = \"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.layers\n",
    "weights, biases = model.layers[1].get_weights()\n",
    "weights\n",
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7446 - accuracy: 0.7591 - val_loss: 0.5327 - val_accuracy: 0.8174\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4929 - accuracy: 0.8288 - val_loss: 0.5604 - val_accuracy: 0.8008\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4472 - accuracy: 0.8441 - val_loss: 0.4516 - val_accuracy: 0.8424\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4201 - accuracy: 0.8534 - val_loss: 0.4265 - val_accuracy: 0.8534\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4001 - accuracy: 0.8605 - val_loss: 0.4092 - val_accuracy: 0.8551\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3840 - accuracy: 0.8653 - val_loss: 0.3927 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3710 - accuracy: 0.8685 - val_loss: 0.3872 - val_accuracy: 0.8642\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3579 - accuracy: 0.8723 - val_loss: 0.3808 - val_accuracy: 0.8656\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3479 - accuracy: 0.8761 - val_loss: 0.3728 - val_accuracy: 0.8690\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3371 - accuracy: 0.8790 - val_loss: 0.3738 - val_accuracy: 0.8653\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3294 - accuracy: 0.8826 - val_loss: 0.3548 - val_accuracy: 0.8729\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3214 - accuracy: 0.8849 - val_loss: 0.3624 - val_accuracy: 0.8705\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3148 - accuracy: 0.8870 - val_loss: 0.3451 - val_accuracy: 0.8762\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3067 - accuracy: 0.8902 - val_loss: 0.3731 - val_accuracy: 0.8662\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3012 - accuracy: 0.8919 - val_loss: 0.3505 - val_accuracy: 0.8766\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2942 - accuracy: 0.8942 - val_loss: 0.3442 - val_accuracy: 0.8768\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2894 - accuracy: 0.8960 - val_loss: 0.3271 - val_accuracy: 0.8819\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2837 - accuracy: 0.8990 - val_loss: 0.3490 - val_accuracy: 0.8706\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2770 - accuracy: 0.8991 - val_loss: 0.3233 - val_accuracy: 0.8833\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2735 - accuracy: 0.9017 - val_loss: 0.3249 - val_accuracy: 0.8809\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2687 - accuracy: 0.9043 - val_loss: 0.3324 - val_accuracy: 0.8786\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2638 - accuracy: 0.9049 - val_loss: 0.3360 - val_accuracy: 0.8769\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2597 - accuracy: 0.9067 - val_loss: 0.3473 - val_accuracy: 0.8776\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2541 - accuracy: 0.9088 - val_loss: 0.3284 - val_accuracy: 0.8822\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2507 - accuracy: 0.9105 - val_loss: 0.3325 - val_accuracy: 0.8810\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2466 - accuracy: 0.9122 - val_loss: 0.3146 - val_accuracy: 0.8857\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2425 - accuracy: 0.9123 - val_loss: 0.3228 - val_accuracy: 0.8846\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2392 - accuracy: 0.9151 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2349 - accuracy: 0.9161 - val_loss: 0.3198 - val_accuracy: 0.8853\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2304 - accuracy: 0.9183 - val_loss: 0.3425 - val_accuracy: 0.8797\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 80.3591 - accuracy: 0.8278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[80.3591079711914, 0.8277999758720398]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\miner\\AppData\\Local\\Temp/ipykernel_14148/4139436455.py:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Regression MLP using the sequential API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X, X_test, y, y_test = tts(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = tts(X,y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.8443 - val_loss: 0.5388\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.7716 - val_loss: 0.5075\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.4693 - val_loss: 0.4800\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.4514 - val_loss: 0.4660\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 563us/step - loss: 0.4401 - val_loss: 0.4620\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.4307 - val_loss: 0.4600\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.4237 - val_loss: 0.4399\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 696us/step - loss: 0.4181 - val_loss: 0.4370\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.4127 - val_loss: 0.4287\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 599us/step - loss: 0.4077 - val_loss: 0.4240\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.4046 - val_loss: 0.4222\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.4012 - val_loss: 0.4214\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.3965 - val_loss: 0.4211\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.3939 - val_loss: 0.4123\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.3897 - val_loss: 0.4054\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.3883 - val_loss: 0.4104\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.3845 - val_loss: 0.4101\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 598us/step - loss: 0.3861 - val_loss: 0.4001\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 581us/step - loss: 0.3789 - val_loss: 0.3952\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 584us/step - loss: 0.3759 - val_loss: 0.3985\n",
      "162/162 [==============================] - 0s 406us/step - loss: 0.3821\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(30, activation = \"relu\", input_shape=X_train.shape[1:]),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Complex Models Using the Functional API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7911 - accuracy: 0.0029 - val_loss: 0.6066 - val_accuracy: 0.0026\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 740us/step - loss: nan - accuracy: 0.0016 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 618us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 778us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 611us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 662us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 729us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 708us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 697us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 706us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 785us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 803us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 723us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 654us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 727us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 730us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 678us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 648us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=X_train.shape[1:])\n",
    "hidden1 = Dense(30, activation = \"relu\")(input_)\n",
    "hidden2 = Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_],outputs=[output])\n",
    "\n",
    "model.compile(loss = \"mse\",\n",
    "             optimizer = \"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 1.8957 - val_loss: 0.9765\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.8589 - val_loss: 0.7572\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.7038 - val_loss: 0.6686\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 590us/step - loss: 0.6334 - val_loss: 0.6193\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.5925 - val_loss: 0.5890\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.5656 - val_loss: 0.5679\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.5465 - val_loss: 0.5505\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.5319 - val_loss: 0.5386\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.5206 - val_loss: 0.5286\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.5114 - val_loss: 0.5208\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.5035 - val_loss: 0.5154\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.4971 - val_loss: 0.5081\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.4915 - val_loss: 0.5030\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4871 - val_loss: 0.5005\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.4830 - val_loss: 0.4970\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 723us/step - loss: 0.4796 - val_loss: 0.4933\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.4765 - val_loss: 0.4916\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.4737 - val_loss: 0.4893\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.4713 - val_loss: 0.4880\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.4690 - val_loss: 0.4837\n",
      "162/162 [==============================] - 0s 466us/step - loss: 0.4713\n"
     ]
    }
   ],
   "source": [
    "input_A = Input(shape=[5])\n",
    "input_B = Input(shape=[6])\n",
    "\n",
    "hidden1 = Dense(30, activation = \"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B],outputs=[output])\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs = 20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_tst= model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using the Subclassing API to Build Dynamic Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer concatenate_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/20\n",
      "  1/363 [..............................] - ETA: 0s - loss: 8.0900 - output_1_loss: 8.3360 - output_2_loss: 5.8759 - output_1_accuracy: 0.0000e+00 - output_2_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.0193 - output_1_loss: 0.8837 - output_2_loss: 2.2397 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0029 - val_loss: 0.6477 - val_output_1_loss: 0.5665 - val_output_2_loss: 1.3786 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.5891 - output_1_loss: 0.5255 - output_2_loss: 1.1617 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.5618 - val_output_1_loss: 0.5086 - val_output_2_loss: 1.0402 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.5268 - output_1_loss: 0.4781 - output_2_loss: 0.9648 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.5364 - val_output_1_loss: 0.4966 - val_output_2_loss: 0.8947 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.4987 - output_1_loss: 0.4613 - output_2_loss: 0.8358 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.5371 - val_output_1_loss: 0.5065 - val_output_2_loss: 0.8130 - val_output_1_accuracy: 0.0023 - val_output_2_accuracy: 0.0028\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.4839 - output_1_loss: 0.4529 - output_2_loss: 0.7635 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4892 - val_output_1_loss: 0.4611 - val_output_2_loss: 0.7421 - val_output_1_accuracy: 0.0023 - val_output_2_accuracy: 0.0028\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.4683 - output_1_loss: 0.4411 - output_2_loss: 0.7135 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4968 - val_output_1_loss: 0.4744 - val_output_2_loss: 0.6987 - val_output_1_accuracy: 0.0023 - val_output_2_accuracy: 0.0028\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.4570 - output_1_loss: 0.4324 - output_2_loss: 0.6785 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4768 - val_output_1_loss: 0.4544 - val_output_2_loss: 0.6782 - val_output_1_accuracy: 0.0023 - val_output_2_accuracy: 0.0028\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.4483 - output_1_loss: 0.4251 - output_2_loss: 0.6575 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4663 - val_output_1_loss: 0.4443 - val_output_2_loss: 0.6636 - val_output_1_accuracy: 0.0023 - val_output_2_accuracy: 0.0028\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.4408 - output_1_loss: 0.4187 - output_2_loss: 0.6395 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.4498 - val_output_1_loss: 0.4291 - val_output_2_loss: 0.6358 - val_output_1_accuracy: 0.0023 - val_output_2_accuracy: 0.0028\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4378 - output_1_loss: 0.4170 - output_2_loss: 0.6251 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4544 - val_output_1_loss: 0.4347 - val_output_2_loss: 0.6317 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4313 - output_1_loss: 0.4113 - output_2_loss: 0.6114 - output_1_accuracy: 0.0028 - output_2_accuracy: 0.0030 - val_loss: 0.4357 - val_output_1_loss: 0.4164 - val_output_2_loss: 0.6096 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.4204 - output_1_loss: 0.4004 - output_2_loss: 0.6005 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4394 - val_output_1_loss: 0.4212 - val_output_2_loss: 0.6033 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.4157 - output_1_loss: 0.3960 - output_2_loss: 0.5932 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.4297 - val_output_1_loss: 0.4111 - val_output_2_loss: 0.5968 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.4088 - output_1_loss: 0.3895 - output_2_loss: 0.5827 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4143 - val_output_1_loss: 0.3957 - val_output_2_loss: 0.5818 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.4043 - output_1_loss: 0.3853 - output_2_loss: 0.5753 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.4154 - val_output_1_loss: 0.3980 - val_output_2_loss: 0.5722 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.3975 - output_1_loss: 0.3787 - output_2_loss: 0.5662 - output_1_accuracy: 0.0030 - output_2_accuracy: 0.0030 - val_loss: 0.4170 - val_output_1_loss: 0.3998 - val_output_2_loss: 0.5722 - val_output_1_accuracy: 0.0028 - val_output_2_accuracy: 0.0028\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.3941 - output_1_loss: 0.3757 - output_2_loss: 0.5598 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.4010 - val_output_1_loss: 0.3833 - val_output_2_loss: 0.5598 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.3945 - output_1_loss: 0.3769 - output_2_loss: 0.5527 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.4018 - val_output_1_loss: 0.3855 - val_output_2_loss: 0.5481 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3887 - output_1_loss: 0.3711 - output_2_loss: 0.5471 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.3947 - val_output_1_loss: 0.3776 - val_output_2_loss: 0.5486 - val_output_1_accuracy: 0.0028 - val_output_2_accuracy: 0.0028\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.3889 - output_1_loss: 0.3719 - output_2_loss: 0.5416 - output_1_accuracy: 0.0029 - output_2_accuracy: 0.0030 - val_loss: 0.3929 - val_output_1_loss: 0.3768 - val_output_2_loss: 0.5381 - val_output_1_accuracy: 0.0026 - val_output_2_accuracy: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1edca2df7f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units = 30, activation =\"relu\",**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = Dense(units, activation = activation)\n",
    "        self.hidden2 = Dense(units, activation = activation)\n",
    "        self.main_output = Dense(1)\n",
    "        self.aux_output = Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()\n",
    "\n",
    "#to save\n",
    "\n",
    "model.call([X_train_A, X_train_B])\n",
    "model.compile(loss = [\"mse\",\"mse\"],loss_weights = [0.9,0.1], optimizer = \"sgd\", metrics=[\"accuracy\"])\n",
    "model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "#model.save(\"keras_API_model.h5\") #does not work in API subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"keras_API_model.h5\") #does not work in API subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.1763 - val_loss: 0.9826\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.8404 - val_loss: 0.7192\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.6827 - val_loss: 0.6535\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 797us/step - loss: 0.6270 - val_loss: 0.6138\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.5929 - val_loss: 0.5911\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.5692 - val_loss: 0.5729\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 744us/step - loss: 0.5514 - val_loss: 0.5615\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.5374 - val_loss: 0.5515\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 723us/step - loss: 0.5261 - val_loss: 0.5447\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.5170 - val_loss: 0.5453\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.501 - 0s 834us/step - loss: 0.5097 - val_loss: 0.5406\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.5034 - val_loss: 0.5406\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.4982 - val_loss: 0.5204\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 824us/step - loss: 0.4940 - val_loss: 0.5189\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.4902 - val_loss: 0.5207\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4864 - val_loss: 0.5173\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.4838 - val_loss: 0.5078\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 708us/step - loss: 0.4810 - val_loss: 0.5035\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.4791 - val_loss: 0.5091\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.4767 - val_loss: 0.5165\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.4749 - val_loss: 0.5044\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.4728 - val_loss: 0.4940\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.4707 - val_loss: 0.4923\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.4695 - val_loss: 0.4923\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.4676 - val_loss: 0.4921\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.4660 - val_loss: 0.4913\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.466 - 0s 806us/step - loss: 0.4644 - val_loss: 0.4841\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.4626 - val_loss: 0.4906\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 733us/step - loss: 0.4613 - val_loss: 0.4784\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.4597 - val_loss: 0.4797\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 747us/step - loss: 0.4582 - val_loss: 0.4762\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.4565 - val_loss: 0.4787\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 824us/step - loss: 0.4553 - val_loss: 0.4713\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 764us/step - loss: 0.4539 - val_loss: 0.4712\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.4524 - val_loss: 0.4689\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.4510 - val_loss: 0.4704\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 716us/step - loss: 0.4498 - val_loss: 0.4652\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.4482 - val_loss: 0.4675\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 726us/step - loss: 0.4467 - val_loss: 0.4625\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.4456 - val_loss: 0.4627\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4445 - val_loss: 0.4611\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.4432 - val_loss: 0.4619\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.4422 - val_loss: 0.4615\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.4411 - val_loss: 0.4575\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.4400 - val_loss: 0.4590\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.4389 - val_loss: 0.4555\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.4380 - val_loss: 0.4571\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 744us/step - loss: 0.4370 - val_loss: 0.4540\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.4358 - val_loss: 0.4526\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.4352 - val_loss: 0.4551\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.4343 - val_loss: 0.4515\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.4334 - val_loss: 0.4488\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 803us/step - loss: 0.4323 - val_loss: 0.4494\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 767us/step - loss: 0.4316 - val_loss: 0.4484\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.4304 - val_loss: 0.4540\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.4299 - val_loss: 0.4493\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.4285 - val_loss: 0.4515\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.4279 - val_loss: 0.4434\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.432 - 0s 756us/step - loss: 0.4270 - val_loss: 0.4426\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.4262 - val_loss: 0.4457\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.4254 - val_loss: 0.4448\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 752us/step - loss: 0.4244 - val_loss: 0.4410\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4236 - val_loss: 0.4396\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.4228 - val_loss: 0.4377\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.4219 - val_loss: 0.4399\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4213 - val_loss: 0.4387\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.420 - 0s 815us/step - loss: 0.4204 - val_loss: 0.4367\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.4195 - val_loss: 0.4345\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.4186 - val_loss: 0.4335\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.4180 - val_loss: 0.4335\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4365\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.4161 - val_loss: 0.4321\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.4157 - val_loss: 0.4319\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.4150 - val_loss: 0.4310\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.4144 - val_loss: 0.4306\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.4134 - val_loss: 0.4306\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.4127 - val_loss: 0.4272\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.4119 - val_loss: 0.4283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.4113 - val_loss: 0.4267\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.4106 - val_loss: 0.4255\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4098 - val_loss: 0.4261\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.4090 - val_loss: 0.4263\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.4083 - val_loss: 0.4251\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.4073 - val_loss: 0.4255\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4070 - val_loss: 0.4230\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 728us/step - loss: 0.4064 - val_loss: 0.4210\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.4058 - val_loss: 0.4213\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.4049 - val_loss: 0.4240\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 734us/step - loss: 0.4043 - val_loss: 0.4224\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.4034 - val_loss: 0.4200\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.4027 - val_loss: 0.4192\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.4020 - val_loss: 0.4186\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.4016 - val_loss: 0.4203\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 776us/step - loss: 0.4009 - val_loss: 0.4196\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.4000 - val_loss: 0.4194\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.3995 - val_loss: 0.4167\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.3988 - val_loss: 0.4163\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3983 - val_loss: 0.4160\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.3976 - val_loss: 0.4185\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3970 - val_loss: 0.4162\n",
      "162/162 [==============================] - 0s 455us/step - loss: 0.3959\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDC99B04C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "input_A = Input(shape=[5])\n",
    "input_B = Input(shape=[6])\n",
    "\n",
    "hidden1 = Dense(30, activation = \"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B],outputs=[output])\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"keras_wideanddeep.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping( patience = 10, restore_best_weights = True)\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), \n",
    "                    y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid), \n",
    "                    callbacks = [checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "mse_tst= model.evaluate((X_test_A, X_test_B),y_test)\n",
    "\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"keras_wideanddeep.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorBoard for Viz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/363 [..............................] - ETA: 1:13 - loss: 6.8315WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.4058s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.1517 - val_loss: 1.2979\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 751us/step - loss: 1.0161 - val_loss: 0.8306\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.7751 - val_loss: 0.7270\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.6946 - val_loss: 0.6764\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 723us/step - loss: 0.6500 - val_loss: 0.6455\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.6194 - val_loss: 0.6217\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.5963 - val_loss: 0.6043\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.5782 - val_loss: 0.5914\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.5635 - val_loss: 0.5812\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.5515 - val_loss: 0.5740\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 684us/step - loss: 0.5415 - val_loss: 0.5628\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.5329 - val_loss: 0.5599\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.5257 - val_loss: 0.5549\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.5197 - val_loss: 0.5443\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.5142 - val_loss: 0.5406\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.5097 - val_loss: 0.5375\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.5057 - val_loss: 0.5347\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 716us/step - loss: 0.5021 - val_loss: 0.5307\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 681us/step - loss: 0.4990 - val_loss: 0.5305\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 752us/step - loss: 0.4963 - val_loss: 0.5255\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.4938 - val_loss: 0.5251\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.4915 - val_loss: 0.5229\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 723us/step - loss: 0.4894 - val_loss: 0.5222\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.4875 - val_loss: 0.5162\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4856 - val_loss: 0.5182\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.4840 - val_loss: 0.5142\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.4824 - val_loss: 0.5099\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.4809 - val_loss: 0.5086\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.4793 - val_loss: 0.5071\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 728us/step - loss: 0.4781 - val_loss: 0.5057\n",
      "162/162 [==============================] - 0s 617us/step - loss: 0.4818\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDCFE76AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "input_A = Input(shape=[5])\n",
    "input_B = Input(shape=[6])\n",
    "\n",
    "hidden1 = Dense(30, activation = \"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B],outputs=[output])\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"keras_wideanddeep.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping( patience = 10, restore_best_weights = True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), \n",
    "                    y_train, \n",
    "                    epochs = 30, \n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid), \n",
    "                    callbacks = [checkpoint_cb, early_stopping_cb, tensorboard_cb])\n",
    "\n",
    "mse_tst= model.evaluate((X_test_A, X_test_B),y_test)\n",
    "\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine Tuning Neural Net HyperParams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 3e-3, input_shape=[8]):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape = input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation = \"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer = optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/363 [..............................] - ETA: 0s - loss: 6.6606WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 926us/step - loss: 1.4581 - val_loss: 0.7428\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.6903 - val_loss: 0.6431\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 681us/step - loss: 0.6015 - val_loss: 0.5831\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.5504 - val_loss: 0.5441\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.5184 - val_loss: 0.5230\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 579us/step - loss: 0.4996 - val_loss: 0.5075\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.4868 - val_loss: 0.4989\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.4781 - val_loss: 0.4896\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.4713 - val_loss: 0.4840\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.4650 - val_loss: 0.4793\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.4610 - val_loss: 0.4733\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 614us/step - loss: 0.4557 - val_loss: 0.4721\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.4526 - val_loss: 0.4739\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.4492 - val_loss: 0.4644\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.4463 - val_loss: 0.4625\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.4432 - val_loss: 0.4612\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.4408 - val_loss: 0.4601\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 593us/step - loss: 0.4406 - val_loss: 0.4584\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.4365 - val_loss: 0.4569\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 587us/step - loss: 0.4367 - val_loss: 0.4540\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.4330 - val_loss: 0.4526\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.4315 - val_loss: 0.4534\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4301 - val_loss: 0.4506\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4278 - val_loss: 0.4504\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.4278 - val_loss: 0.4490\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.4250 - val_loss: 0.4497\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4233 - val_loss: 0.4450\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.4222 - val_loss: 0.4452\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.4209 - val_loss: 0.4458\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.4210 - val_loss: 0.4437\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4173 - val_loss: 0.4436\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 604us/step - loss: 0.4155 - val_loss: 0.4407\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.4158 - val_loss: 0.4497\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.4139 - val_loss: 0.4433\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.4153 - val_loss: 0.4379\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.4129 - val_loss: 0.4368\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4110 - val_loss: 0.4343\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.4106 - val_loss: 0.4344\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 578us/step - loss: 0.4111 - val_loss: 0.4393\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.4122 - val_loss: 0.4337\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 579us/step - loss: 0.4067 - val_loss: 0.4381\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4043 - val_loss: 0.4348\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 580us/step - loss: 0.4056 - val_loss: 0.4308\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 577us/step - loss: 0.4044 - val_loss: 0.4325\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 580us/step - loss: 0.4031 - val_loss: 0.4304\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.4010 - val_loss: 0.4341\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.3996 - val_loss: 0.4257\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 631us/step - loss: 0.3983 - val_loss: 0.4304\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.3970 - val_loss: 0.4269\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 648us/step - loss: 0.3967 - val_loss: 0.4217\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.3958 - val_loss: 0.4213\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.3942 - val_loss: 0.4224\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 653us/step - loss: 0.3924 - val_loss: 0.4241\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.3918 - val_loss: 0.4247\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.3908 - val_loss: 0.4178\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3899 - val_loss: 0.4178\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 593us/step - loss: 0.3884 - val_loss: 0.4165\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.3880 - val_loss: 0.4165\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.3862 - val_loss: 0.4137\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.3874 - val_loss: 0.4181\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.3844 - val_loss: 0.4113\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.3836 - val_loss: 0.4120\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.3824 - val_loss: 0.4127\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 596us/step - loss: 0.3813 - val_loss: 0.4098\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.3804 - val_loss: 0.4156\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.3808 - val_loss: 0.4121\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 593us/step - loss: 0.3793 - val_loss: 0.4111\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 581us/step - loss: 0.3783 - val_loss: 0.4045\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.3778 - val_loss: 0.4075\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.3764 - val_loss: 0.4018\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.3757 - val_loss: 0.4069\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.3749 - val_loss: 0.4004\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 634us/step - loss: 0.3736 - val_loss: 0.4001\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.3734 - val_loss: 0.4009\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 568us/step - loss: 0.3718 - val_loss: 0.4031\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.3714 - val_loss: 0.4001\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 632us/step - loss: 0.3704 - val_loss: 0.4026\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 648us/step - loss: 0.3699 - val_loss: 0.4069\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 588us/step - loss: 0.3685 - val_loss: 0.4037\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 655us/step - loss: 0.3675 - val_loss: 0.3952\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.3674 - val_loss: 0.3944\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.3662 - val_loss: 0.3968\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 612us/step - loss: 0.3663 - val_loss: 0.4085\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.3651 - val_loss: 0.3979\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.3648 - val_loss: 0.4023\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 646us/step - loss: 0.3635 - val_loss: 0.3953\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 629us/step - loss: 0.3624 - val_loss: 0.3968\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.3635 - val_loss: 0.4117\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 634us/step - loss: 0.3625 - val_loss: 0.3991\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3609 - val_loss: 0.3976\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 643us/step - loss: 0.3594 - val_loss: 0.3895\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.3595 - val_loss: 0.3892\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.3587 - val_loss: 0.3870\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.3606 - val_loss: 0.3846\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 583us/step - loss: 0.3573 - val_loss: 0.3937\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3577 - val_loss: 0.3866\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 578us/step - loss: 0.3569 - val_loss: 0.3842\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.3558 - val_loss: 0.3924\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.3552 - val_loss: 0.3852\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.3546 - val_loss: 0.3882\n",
      "162/162 [==============================] - 0s 428us/step - loss: 0.3633\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDEC23DE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(X_train, y_train, epochs = 100, \n",
    "              validation_data =(X_valid, y_valid), \n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3056 - val_loss: 0.7817\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.7902 - val_loss: 0.6707\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.6414 - val_loss: 0.6035\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.5775 - val_loss: 0.5546\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5341 - val_loss: 0.5219\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.5038 - val_loss: 0.4997\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4821 - val_loss: 0.4853\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4664 - val_loss: 0.4740\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4549 - val_loss: 0.4669\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.4456 - val_loss: 0.4606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4392 - val_loss: 0.4562\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4338 - val_loss: 0.4523\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4287 - val_loss: 0.4505\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4246 - val_loss: 0.4467\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4212 - val_loss: 0.4437\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4169 - val_loss: 0.4419\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4155 - val_loss: 0.4388\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.4122 - val_loss: 0.4376\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4097 - val_loss: 0.4336\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.4075 - val_loss: 0.4341\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4058 - val_loss: 0.4316\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4027 - val_loss: 0.4311\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4011 - val_loss: 0.4290\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3992 - val_loss: 0.4272\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3983 - val_loss: 0.4241\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3958 - val_loss: 0.4242\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3942 - val_loss: 0.4230\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3924 - val_loss: 0.4217\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3919 - val_loss: 0.4204\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3899 - val_loss: 0.4189\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3885 - val_loss: 0.4172\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3876 - val_loss: 0.4190\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.3855 - val_loss: 0.4163\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3846 - val_loss: 0.4137\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3834 - val_loss: 0.4143\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3815 - val_loss: 0.4131\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3814 - val_loss: 0.4100\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3789 - val_loss: 0.4128\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3779 - val_loss: 0.4100\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3798 - val_loss: 0.4076\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3754 - val_loss: 0.4091\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3755 - val_loss: 0.4059\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.3742 - val_loss: 0.4066\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3727 - val_loss: 0.4054\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3728 - val_loss: 0.4028\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3706 - val_loss: 0.4050\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3701 - val_loss: 0.4023\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3683 - val_loss: 0.4010\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3682 - val_loss: 0.4007\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3667 - val_loss: 0.4011\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.376 - 0s 775us/step - loss: 0.3669 - val_loss: 0.3987\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3646 - val_loss: 0.3993\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3641 - val_loss: 0.3976\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3628 - val_loss: 0.3982\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3637 - val_loss: 0.3957\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3607 - val_loss: 0.3944\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3603 - val_loss: 0.3950\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3592 - val_loss: 0.3965\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3584 - val_loss: 0.3945\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3580 - val_loss: 0.3921\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3572 - val_loss: 0.3903\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3577 - val_loss: 0.3914\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3546 - val_loss: 0.3889\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3549 - val_loss: 0.3891\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3534 - val_loss: 0.3880\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3528 - val_loss: 0.3867\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3524 - val_loss: 0.3866\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.3513 - val_loss: 0.3858\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3506 - val_loss: 0.3840\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3528 - val_loss: 0.3844\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3482 - val_loss: 0.3839\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3482 - val_loss: 0.3840\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3489 - val_loss: 0.3830\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3505 - val_loss: 0.3879\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3487 - val_loss: 0.3811\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3466 - val_loss: 0.3799\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.3433 - val_loss: 0.3802\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3437 - val_loss: 0.3813\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 695us/step - loss: 0.3430 - val_loss: 0.3791\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.3418 - val_loss: 0.3768\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3420 - val_loss: 0.3769\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.3409 - val_loss: 0.3770\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3396 - val_loss: 0.3751\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3400 - val_loss: 0.3816\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.3396 - val_loss: 0.3745\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3383 - val_loss: 0.3733\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3373 - val_loss: 0.3726\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3398 - val_loss: 0.3729\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3361 - val_loss: 0.3716\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.3363 - val_loss: 0.3718\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3344 - val_loss: 0.3729\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3345 - val_loss: 0.3748\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3347 - val_loss: 0.3722\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3339 - val_loss: 0.3741\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3328 - val_loss: 0.3710\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3353 - val_loss: 0.3702\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.3307 - val_loss: 0.3693\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3323 - val_loss: 0.3686\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3312 - val_loss: 0.3681\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3303 - val_loss: 0.3670\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.1889WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 589us/step - loss: 0.3505\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 5.2453WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "166/242 [===================>..........] - ETA: 0s - loss: 1.9566WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5857 - val_loss: 0.7076\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6451 - val_loss: 0.6247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.5868 - val_loss: 0.5823\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.5464 - val_loss: 0.5506\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.5188 - val_loss: 0.5276\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4984 - val_loss: 0.5152\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4820 - val_loss: 0.5026\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4749 - val_loss: 0.4968\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4629 - val_loss: 0.4865\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4581 - val_loss: 0.4732\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4513 - val_loss: 0.4840\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4498 - val_loss: 0.4850\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.4444 - val_loss: 0.4614\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4390 - val_loss: 0.4677\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.4367 - val_loss: 0.4606\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4336 - val_loss: 0.4575\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4310 - val_loss: 0.4539\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4284 - val_loss: 0.4539\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4272 - val_loss: 0.4538\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4264 - val_loss: 0.4448\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.4227 - val_loss: 0.4430\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.4216 - val_loss: 0.4410\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4193 - val_loss: 0.4420\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4174 - val_loss: 0.4403\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4157 - val_loss: 0.4357\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4147 - val_loss: 0.4376\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4124 - val_loss: 0.4378\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4109 - val_loss: 0.4345\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4102 - val_loss: 0.4388\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4081 - val_loss: 0.4312\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.4075 - val_loss: 0.4300\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4074 - val_loss: 0.4312\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4052 - val_loss: 0.4302\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4077 - val_loss: 0.4303\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4015 - val_loss: 0.4311\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.4003 - val_loss: 0.4281\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3994 - val_loss: 0.4384\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3978 - val_loss: 0.4266\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3966 - val_loss: 0.4234\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3956 - val_loss: 0.4253\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3958 - val_loss: 0.4242\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.3932 - val_loss: 0.4220\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3925 - val_loss: 0.4220\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3917 - val_loss: 0.4180\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3900 - val_loss: 0.4166\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3901 - val_loss: 0.4205\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3883 - val_loss: 0.4175\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3862 - val_loss: 0.4174\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.3856 - val_loss: 0.4179\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 690us/step - loss: 0.3834 - val_loss: 0.4272\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3833 - val_loss: 0.4109\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3952 - val_loss: 0.4121\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3869 - val_loss: 0.4120\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3790 - val_loss: 0.4128\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3784 - val_loss: 0.4104\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3769 - val_loss: 0.4099\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3761 - val_loss: 0.4078\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3767 - val_loss: 0.4046\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3746 - val_loss: 0.4044\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3727 - val_loss: 0.4044\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3722 - val_loss: 0.4028\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3713 - val_loss: 0.4042\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3695 - val_loss: 0.3992\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3687 - val_loss: 0.4005\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3674 - val_loss: 0.3993\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3672 - val_loss: 0.3979\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3672 - val_loss: 0.3994\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3644 - val_loss: 0.3981\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3644 - val_loss: 0.3968\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3629 - val_loss: 0.3965\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3617 - val_loss: 0.3935\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3613 - val_loss: 0.3941\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3602 - val_loss: 0.3912\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3588 - val_loss: 0.3916\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3584 - val_loss: 0.3922\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3579 - val_loss: 0.3917\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3562 - val_loss: 0.3893\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3578 - val_loss: 0.3897\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3552 - val_loss: 0.3884\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3536 - val_loss: 0.3896\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3555 - val_loss: 0.3876\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3551 - val_loss: 0.3856\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3517 - val_loss: 0.3876\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3509 - val_loss: 0.3849\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3500 - val_loss: 0.3853\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.3529 - val_loss: 0.3872\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3501 - val_loss: 0.3837\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3485 - val_loss: 0.3905\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3480 - val_loss: 0.3838\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3470 - val_loss: 0.3811\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3449 - val_loss: 0.3802\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3444 - val_loss: 0.3784\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3498 - val_loss: 0.3785\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3432 - val_loss: 0.3770\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3433 - val_loss: 0.3778\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3410 - val_loss: 0.3778\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3422 - val_loss: 0.3770\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3394 - val_loss: 0.3774\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3398 - val_loss: 0.3767\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3383 - val_loss: 0.3739\n",
      "121/121 [==============================] - 0s 495us/step - loss: 0.3346\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2432 - val_loss: 0.7572\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.6934 - val_loss: 0.6702\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.6178 - val_loss: 0.6187\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5676 - val_loss: 0.5781\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5329 - val_loss: 0.5475\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5067 - val_loss: 0.5233\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4859 - val_loss: 0.5072\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4704 - val_loss: 0.4933\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4583 - val_loss: 0.4835\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4483 - val_loss: 0.4734\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4398 - val_loss: 0.4667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4335 - val_loss: 0.4608\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4281 - val_loss: 0.4557\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.4230 - val_loss: 0.4546\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4194 - val_loss: 0.4482\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.4152 - val_loss: 0.4454\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4441\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4091 - val_loss: 0.4406\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4065 - val_loss: 0.4378\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4038 - val_loss: 0.4347\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4020 - val_loss: 0.4335\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.3999 - val_loss: 0.4311\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.3982 - val_loss: 0.4321\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.3964 - val_loss: 0.4289\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3948 - val_loss: 0.4299\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3931 - val_loss: 0.4277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3913 - val_loss: 0.4248\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 791us/step - loss: 0.3899 - val_loss: 0.4238\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3882 - val_loss: 0.4230\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3873 - val_loss: 0.4241\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3854 - val_loss: 0.4194\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3840 - val_loss: 0.4205\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3827 - val_loss: 0.4179\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3811 - val_loss: 0.4178\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3801 - val_loss: 0.4156\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.3788 - val_loss: 0.4157\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3773 - val_loss: 0.4156\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3764 - val_loss: 0.4155\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3748 - val_loss: 0.4150\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3732 - val_loss: 0.4120\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.369 - 0s 778us/step - loss: 0.3721 - val_loss: 0.4103\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.3712 - val_loss: 0.4105\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3701 - val_loss: 0.4118\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3688 - val_loss: 0.4068\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3680 - val_loss: 0.4067\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3658 - val_loss: 0.4080\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3657 - val_loss: 0.4067\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.3649 - val_loss: 0.4042\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3633 - val_loss: 0.4031\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3622 - val_loss: 0.4035\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.3613 - val_loss: 0.4005\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3601 - val_loss: 0.3986\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3589 - val_loss: 0.3999\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3578 - val_loss: 0.4003\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3571 - val_loss: 0.3993\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3558 - val_loss: 0.3972\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3550 - val_loss: 0.3973\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.3538 - val_loss: 0.3958\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3529 - val_loss: 0.3942\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3521 - val_loss: 0.3949\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3515 - val_loss: 0.3919\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3501 - val_loss: 0.3933\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3493 - val_loss: 0.3905\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3482 - val_loss: 0.3905\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3475 - val_loss: 0.3899\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3465 - val_loss: 0.3888\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3456 - val_loss: 0.3902\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3449 - val_loss: 0.3883\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3435 - val_loss: 0.3868\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3428 - val_loss: 0.3852\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3418 - val_loss: 0.3858\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3415 - val_loss: 0.3850\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3404 - val_loss: 0.3862\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3393 - val_loss: 0.3837\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3389 - val_loss: 0.3807\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3378 - val_loss: 0.3829\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3369 - val_loss: 0.3805\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3365 - val_loss: 0.3811\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3356 - val_loss: 0.3790\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3347 - val_loss: 0.3789\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3343 - val_loss: 0.3785\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3334 - val_loss: 0.3798\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3322 - val_loss: 0.3772\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3320 - val_loss: 0.3789\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3312 - val_loss: 0.3790\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3303 - val_loss: 0.3779\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3301 - val_loss: 0.3742\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3292 - val_loss: 0.3731\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3286 - val_loss: 0.3741\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3282 - val_loss: 0.3761\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3272 - val_loss: 0.3766\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.3265 - val_loss: 0.3704\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3252 - val_loss: 0.3740\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3251 - val_loss: 0.3709\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3248 - val_loss: 0.3704\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3241 - val_loss: 0.3710\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3230 - val_loss: 0.3702\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3224 - val_loss: 0.3691\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3220 - val_loss: 0.3663\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3215 - val_loss: 0.3673\n",
      "121/121 [==============================] - 0s 511us/step - loss: 0.3672\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6642 - val_loss: 2.0399\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 1.5192 - val_loss: 1.1694\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 1.0094 - val_loss: 0.8850\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.8317 - val_loss: 0.7835\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.7628 - val_loss: 0.7415\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 769us/step - loss: 0.7301 - val_loss: 0.7179\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.7096 - val_loss: 0.7007\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.6937 - val_loss: 0.6863\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.6800 - val_loss: 0.6738\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.6679 - val_loss: 0.6622\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.6565 - val_loss: 0.6516\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.6460 - val_loss: 0.6420\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.6362 - val_loss: 0.6327\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.6268 - val_loss: 0.6243\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.6182 - val_loss: 0.6165\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.6098 - val_loss: 0.6090\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6021 - val_loss: 0.6018\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5947 - val_loss: 0.5949\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5876 - val_loss: 0.5887\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5810 - val_loss: 0.5823\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5747 - val_loss: 0.5767\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.5686 - val_loss: 0.5711\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.5629 - val_loss: 0.5660\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5574 - val_loss: 0.5609\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5522 - val_loss: 0.5565\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5473 - val_loss: 0.5522\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5426 - val_loss: 0.5482\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5381 - val_loss: 0.5446\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.5339 - val_loss: 0.5409\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5298 - val_loss: 0.5376\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.5259 - val_loss: 0.5342\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5223 - val_loss: 0.5311\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.5188 - val_loss: 0.5283\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.5154 - val_loss: 0.5254\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5122 - val_loss: 0.5227\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5093 - val_loss: 0.5207\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5064 - val_loss: 0.5189\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5035 - val_loss: 0.5161\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5012 - val_loss: 0.5146\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4987 - val_loss: 0.5129\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.4963 - val_loss: 0.5102\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4942 - val_loss: 0.5090\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.4920 - val_loss: 0.5068\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4899 - val_loss: 0.5052\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4880 - val_loss: 0.5042\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4862 - val_loss: 0.5023\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4843 - val_loss: 0.5007\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4826 - val_loss: 0.4993\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4808 - val_loss: 0.4977\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.4793 - val_loss: 0.4964\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4777 - val_loss: 0.4951\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.4762 - val_loss: 0.4944\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4747 - val_loss: 0.4923\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4733 - val_loss: 0.4917\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4719 - val_loss: 0.4892\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4706 - val_loss: 0.4885\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4693 - val_loss: 0.4877\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4681 - val_loss: 0.4864\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.4669 - val_loss: 0.4853\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4658 - val_loss: 0.4847\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.4647 - val_loss: 0.4839\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4637 - val_loss: 0.4828\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4627 - val_loss: 0.4815\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4617 - val_loss: 0.4802\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4607 - val_loss: 0.4798\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4597 - val_loss: 0.4788\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4589 - val_loss: 0.4779\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4579 - val_loss: 0.4766\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4571 - val_loss: 0.4764\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4563 - val_loss: 0.4759\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4554 - val_loss: 0.4748\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4546 - val_loss: 0.4738\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4539 - val_loss: 0.4731\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.4530 - val_loss: 0.4735\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4524 - val_loss: 0.4727\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4516 - val_loss: 0.4714\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4509 - val_loss: 0.4709\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4502 - val_loss: 0.4702\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4495 - val_loss: 0.4699\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4488 - val_loss: 0.4691\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4481 - val_loss: 0.4683\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4475 - val_loss: 0.4676\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4468 - val_loss: 0.4670\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4462 - val_loss: 0.4664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4456 - val_loss: 0.4661\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.4450 - val_loss: 0.4657\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4444 - val_loss: 0.4649\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4438 - val_loss: 0.4643\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4432 - val_loss: 0.4636\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4427 - val_loss: 0.4632\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4420 - val_loss: 0.4634\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4416 - val_loss: 0.4626\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4410 - val_loss: 0.4622\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.4405 - val_loss: 0.4617\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4399 - val_loss: 0.4615\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4394 - val_loss: 0.4603\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4389 - val_loss: 0.4603\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4384 - val_loss: 0.4594\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4378 - val_loss: 0.4588\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4373 - val_loss: 0.4591\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2916WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 519us/step - loss: 0.4414\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1779 - val_loss: 2.4763\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 1.5936 - val_loss: 1.3914\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 1.0583 - val_loss: 0.9712\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.8691 - val_loss: 0.8329\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.7941 - val_loss: 0.7794\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.7567 - val_loss: 0.7519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.7332 - val_loss: 0.7340\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.7164 - val_loss: 0.7188\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.7029 - val_loss: 0.7068\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.6912 - val_loss: 0.6962\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.6807 - val_loss: 0.6870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.6711 - val_loss: 0.6788\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 653us/step - loss: 0.6621 - val_loss: 0.6723\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.6538 - val_loss: 0.6648\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.6458 - val_loss: 0.6567\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.6383 - val_loss: 0.6508\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.6310 - val_loss: 0.6440\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.6242 - val_loss: 0.6387\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.6176 - val_loss: 0.6335\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.6113 - val_loss: 0.6289\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.6054 - val_loss: 0.6224\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.5995 - val_loss: 0.6165\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.5939 - val_loss: 0.6137\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5887 - val_loss: 0.6084\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5835 - val_loss: 0.6035\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5785 - val_loss: 0.6007\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.5736 - val_loss: 0.5951\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5690 - val_loss: 0.5904\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5645 - val_loss: 0.5887\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5602 - val_loss: 0.5838\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5561 - val_loss: 0.5810\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.5521 - val_loss: 0.5774\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5482 - val_loss: 0.5755\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5445 - val_loss: 0.5704\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5409 - val_loss: 0.5678\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5374 - val_loss: 0.5649\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5341 - val_loss: 0.5605\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5310 - val_loss: 0.5602\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.5278 - val_loss: 0.5543\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5249 - val_loss: 0.5562\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5222 - val_loss: 0.5542\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5194 - val_loss: 0.5491\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5168 - val_loss: 0.5465\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5142 - val_loss: 0.5471\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5119 - val_loss: 0.5431\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5096 - val_loss: 0.5402\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.5072 - val_loss: 0.5373\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.5051 - val_loss: 0.5370\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.5030 - val_loss: 0.5321\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5010 - val_loss: 0.5347\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4991 - val_loss: 0.5331\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.4973 - val_loss: 0.5302\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4954 - val_loss: 0.5278\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.5240\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4922 - val_loss: 0.5240\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4905 - val_loss: 0.5253\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4891 - val_loss: 0.5252\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4878 - val_loss: 0.5212\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.4864 - val_loss: 0.5198\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4851 - val_loss: 0.5188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4838 - val_loss: 0.5162\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4826 - val_loss: 0.5138\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4815 - val_loss: 0.5141\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4803 - val_loss: 0.5146\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4793 - val_loss: 0.5097\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4783 - val_loss: 0.5117\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4773 - val_loss: 0.5123\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4765 - val_loss: 0.5090\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.4755 - val_loss: 0.5080\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.4745 - val_loss: 0.5086\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4736 - val_loss: 0.5046\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4727 - val_loss: 0.5020\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4719 - val_loss: 0.5021\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4710 - val_loss: 0.5005\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4702 - val_loss: 0.4997\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4695 - val_loss: 0.4966\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4687 - val_loss: 0.4956\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4679 - val_loss: 0.4966\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4671 - val_loss: 0.4935\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4664 - val_loss: 0.4930\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4657 - val_loss: 0.4929\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4651 - val_loss: 0.4918\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4643 - val_loss: 0.4905\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4637 - val_loss: 0.4922\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.4632 - val_loss: 0.4918\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4626 - val_loss: 0.4886\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4619 - val_loss: 0.4880\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.4613 - val_loss: 0.4900\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4609 - val_loss: 0.4872\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4602 - val_loss: 0.4866\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4595 - val_loss: 0.4892\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4592 - val_loss: 0.4834\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4587 - val_loss: 0.4836\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4581 - val_loss: 0.4812\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.4576 - val_loss: 0.4819\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4571 - val_loss: 0.4835\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.4566 - val_loss: 0.4812\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4560 - val_loss: 0.4786\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4555 - val_loss: 0.4828\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4551 - val_loss: 0.4801\n",
      "121/121 [==============================] - 0s 409us/step - loss: 0.4367\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9060 - val_loss: 1.6398\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 1.1973 - val_loss: 1.0993\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.9348 - val_loss: 0.9221\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.8472 - val_loss: 0.8393\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.7964 - val_loss: 0.7910\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.7599 - val_loss: 0.7610\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.7310 - val_loss: 0.7360\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.7070 - val_loss: 0.7172\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.6866 - val_loss: 0.6999\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.6687 - val_loss: 0.6839\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.6529 - val_loss: 0.6701\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.6388 - val_loss: 0.6579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.6262 - val_loss: 0.6458\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.6148 - val_loss: 0.6365\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.6045 - val_loss: 0.6276\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.5950 - val_loss: 0.6189\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5861 - val_loss: 0.6119\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5780 - val_loss: 0.6044\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.5705 - val_loss: 0.5981\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5635 - val_loss: 0.5917\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5570 - val_loss: 0.5842\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5509 - val_loss: 0.5793\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5451 - val_loss: 0.5729\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.5397 - val_loss: 0.5687\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5345 - val_loss: 0.5646\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.5296 - val_loss: 0.5611\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5250 - val_loss: 0.5543\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5207 - val_loss: 0.5511\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5167 - val_loss: 0.5479\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5128 - val_loss: 0.5450\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.5092 - val_loss: 0.5399\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5058 - val_loss: 0.5374\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.5025 - val_loss: 0.5343\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4995 - val_loss: 0.5323\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4967 - val_loss: 0.5287\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4941 - val_loss: 0.5274\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.4915 - val_loss: 0.5283\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4893 - val_loss: 0.5240\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 728us/step - loss: 0.4870 - val_loss: 0.5209\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.4849 - val_loss: 0.5196\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.4828 - val_loss: 0.5159\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4810 - val_loss: 0.5152\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4792 - val_loss: 0.5141\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4776 - val_loss: 0.5132\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.4760 - val_loss: 0.5099\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.4745 - val_loss: 0.5084\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4730 - val_loss: 0.5080\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.4716 - val_loss: 0.5056\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4702 - val_loss: 0.5065\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4690 - val_loss: 0.5032\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.4677 - val_loss: 0.5018\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4665 - val_loss: 0.5002\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4654 - val_loss: 0.4994\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.4642 - val_loss: 0.4984\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4631 - val_loss: 0.4979\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.4621 - val_loss: 0.4950\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.4610 - val_loss: 0.4953\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4600 - val_loss: 0.4954\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4591 - val_loss: 0.4924\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4583 - val_loss: 0.4924\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4573 - val_loss: 0.4895\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4566 - val_loss: 0.4895\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4557 - val_loss: 0.4890\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.4548 - val_loss: 0.4868\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4539 - val_loss: 0.4854\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4533 - val_loss: 0.4858\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4525 - val_loss: 0.4854\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4517 - val_loss: 0.4850\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4508 - val_loss: 0.4815\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4503 - val_loss: 0.4822\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4495 - val_loss: 0.4801\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4488 - val_loss: 0.4810\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4801\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4474 - val_loss: 0.4787\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4468 - val_loss: 0.4782\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4461 - val_loss: 0.4778\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4454 - val_loss: 0.4760\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4447 - val_loss: 0.4773\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4442 - val_loss: 0.4757\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.425 - 0s 783us/step - loss: 0.4435 - val_loss: 0.4741\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4429 - val_loss: 0.4741\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.4423 - val_loss: 0.4734\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4416 - val_loss: 0.4738\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.4410 - val_loss: 0.4715\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4405 - val_loss: 0.4713\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4399 - val_loss: 0.4720\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4394 - val_loss: 0.4694\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4388 - val_loss: 0.4703\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4382 - val_loss: 0.4689\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4377 - val_loss: 0.4686\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4372 - val_loss: 0.4670\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.4367 - val_loss: 0.4670\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4361 - val_loss: 0.4668\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.4356 - val_loss: 0.4659\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4351 - val_loss: 0.4657\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4347 - val_loss: 0.4650\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4342 - val_loss: 0.4645\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4336 - val_loss: 0.4646\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4331 - val_loss: 0.4642\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4326 - val_loss: 0.4625\n",
      "121/121 [==============================] - 0s 443us/step - loss: 0.4591\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8951 - val_loss: 1.1647\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.8340 - val_loss: 0.7160\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.6579 - val_loss: 0.6437\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.6164 - val_loss: 0.6090\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.5929 - val_loss: 0.5903\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5755 - val_loss: 0.5775\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5622 - val_loss: 0.5690\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5520 - val_loss: 0.5640\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.5443 - val_loss: 0.5606\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.5382 - val_loss: 0.5572\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5336 - val_loss: 0.5586\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5301 - val_loss: 0.5563\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5269 - val_loss: 0.5547\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5248 - val_loss: 0.5545\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5237 - val_loss: 0.5571\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5223 - val_loss: 0.5615\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 602us/step - loss: 0.5208 - val_loss: 0.5593\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5204 - val_loss: 0.5620\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5194 - val_loss: 0.5688\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5191 - val_loss: 0.5626\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.5186 - val_loss: 0.5609\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5186 - val_loss: 0.5606\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.5179 - val_loss: 0.5645\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.5181 - val_loss: 0.5625\n",
      "121/121 [==============================] - 0s 498us/step - loss: 0.5195\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7218 - val_loss: 0.9425\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.6923 - val_loss: 0.5861\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.5626 - val_loss: 0.5556\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.5481 - val_loss: 0.5549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5426 - val_loss: 0.5522\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.5385 - val_loss: 0.5476\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5361 - val_loss: 0.5483\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.5335 - val_loss: 0.5581\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5320 - val_loss: 0.5518\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.5304 - val_loss: 0.5600\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5297 - val_loss: 0.5587\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5289 - val_loss: 0.5511\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.5284 - val_loss: 0.5610\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.5281 - val_loss: 0.5584\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.5274 - val_loss: 0.5566\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.5279 - val_loss: 0.5627\n",
      "121/121 [==============================] - 0s 478us/step - loss: 0.5009\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5972 - val_loss: 0.9185\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.6761 - val_loss: 0.6004\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.5607 - val_loss: 0.5761\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.5435 - val_loss: 0.5701\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.5354 - val_loss: 0.5673\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.5300 - val_loss: 0.5650\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5258 - val_loss: 0.5628\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.5222 - val_loss: 0.5675\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5203 - val_loss: 0.5593\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5182 - val_loss: 0.5588\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5165 - val_loss: 0.5570\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5155 - val_loss: 0.5592\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5144 - val_loss: 0.5595\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.5137 - val_loss: 0.5587\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 603us/step - loss: 0.5130 - val_loss: 0.5623\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5125 - val_loss: 0.5646\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.5121 - val_loss: 0.5629\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5115 - val_loss: 0.5668\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5116 - val_loss: 0.5570\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5111 - val_loss: 0.5586\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5111 - val_loss: 0.5554\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.5105 - val_loss: 0.5657\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.5108 - val_loss: 0.5644\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5106 - val_loss: 0.5558\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5105 - val_loss: 0.5575\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5103 - val_loss: 0.5568\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5100 - val_loss: 0.5565\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5100 - val_loss: 0.5551\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.5102 - val_loss: 0.5593\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.5104 - val_loss: 0.5584\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.5102 - val_loss: 0.5565\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5101 - val_loss: 0.5556\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.5100 - val_loss: 0.5550\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.5100 - val_loss: 0.5621\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.5100 - val_loss: 0.5560\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5097 - val_loss: 0.5549\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.5099 - val_loss: 0.5595\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5098 - val_loss: 0.5572\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5098 - val_loss: 0.5613\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5098 - val_loss: 0.5624\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5099 - val_loss: 0.5585\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5099 - val_loss: 0.5567\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5099 - val_loss: 0.5565\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5097 - val_loss: 0.5586\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5096 - val_loss: 0.5542\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5099 - val_loss: 0.5555\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5097 - val_loss: 0.5580\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5567\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5096 - val_loss: 0.5545\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5098 - val_loss: 0.5544\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5095 - val_loss: 0.5631\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5100 - val_loss: 0.5592\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5099 - val_loss: 0.5566\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 734us/step - loss: 0.5098 - val_loss: 0.5571\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5099 - val_loss: 0.5537\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.5096 - val_loss: 0.5511\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5097 - val_loss: 0.5589\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.5098 - val_loss: 0.5564\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5094 - val_loss: 0.5529\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.5100 - val_loss: 0.5545\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.5098 - val_loss: 0.5531\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.5097 - val_loss: 0.5526\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5098 - val_loss: 0.5527\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5099 - val_loss: 0.5526\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5099 - val_loss: 0.5540\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.5097 - val_loss: 0.5524\n",
      "121/121 [==============================] - 0s 427us/step - loss: 0.5368\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8464 - val_loss: 1.2469\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.8875 - val_loss: 0.7789\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.7291 - val_loss: 0.6970\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.6663 - val_loss: 0.6446\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.6208 - val_loss: 0.6079\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5847 - val_loss: 0.5793\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5551 - val_loss: 0.5547\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5315 - val_loss: 0.5359\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5115 - val_loss: 0.5188\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4947 - val_loss: 0.5071\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.4810 - val_loss: 0.4954\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4699 - val_loss: 0.4878\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4608 - val_loss: 0.4824\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.4535 - val_loss: 0.4740\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4470 - val_loss: 0.4684\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4415 - val_loss: 0.4624\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.4367 - val_loss: 0.4584\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4317 - val_loss: 0.4563\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4287 - val_loss: 0.4496\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.4254 - val_loss: 0.4473\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4218 - val_loss: 0.4442\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4190 - val_loss: 0.4413\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4165 - val_loss: 0.4385\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4142 - val_loss: 0.4367\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4120 - val_loss: 0.4345\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.4097 - val_loss: 0.4334\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4077 - val_loss: 0.4321\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4057 - val_loss: 0.4294\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.4036 - val_loss: 0.4279\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4017 - val_loss: 0.4272\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4003 - val_loss: 0.4263\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3986 - val_loss: 0.4238\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3969 - val_loss: 0.4224\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3961 - val_loss: 0.4220\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3946 - val_loss: 0.4201\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3930 - val_loss: 0.4207\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3914 - val_loss: 0.4185\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3911 - val_loss: 0.4176\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3894 - val_loss: 0.4161\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3882 - val_loss: 0.4161\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3873 - val_loss: 0.4141\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3861 - val_loss: 0.4138\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3843 - val_loss: 0.4137\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3838 - val_loss: 0.4116\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3837 - val_loss: 0.4105\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.3820 - val_loss: 0.4098\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.3816 - val_loss: 0.4090\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3801 - val_loss: 0.4078\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3796 - val_loss: 0.4084\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3786 - val_loss: 0.4070\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3783 - val_loss: 0.4055\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3772 - val_loss: 0.4044\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3760 - val_loss: 0.4043\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.3754 - val_loss: 0.4051\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.3750 - val_loss: 0.4023\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.3737 - val_loss: 0.4025\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3727 - val_loss: 0.4000\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3724 - val_loss: 0.4000\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3716 - val_loss: 0.3989\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3711 - val_loss: 0.3986\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3703 - val_loss: 0.3979\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3688 - val_loss: 0.3979\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3686 - val_loss: 0.3988\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3681 - val_loss: 0.3959\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3663 - val_loss: 0.3953\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 767us/step - loss: 0.3671 - val_loss: 0.3988\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3655 - val_loss: 0.4010\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3655 - val_loss: 0.3947\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3647 - val_loss: 0.3933\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3637 - val_loss: 0.3920\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.3630 - val_loss: 0.3922\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3629 - val_loss: 0.3910\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3621 - val_loss: 0.3919\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3619 - val_loss: 0.3915\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3610 - val_loss: 0.3892\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3604 - val_loss: 0.3888\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3601 - val_loss: 0.3903\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3590 - val_loss: 0.3913\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.3586 - val_loss: 0.3880\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3584 - val_loss: 0.3861\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3574 - val_loss: 0.3880\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.3563 - val_loss: 0.3882\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.3569 - val_loss: 0.3845\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3553 - val_loss: 0.3875\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3556 - val_loss: 0.3842\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3543 - val_loss: 0.3828\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3541 - val_loss: 0.3841\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3544 - val_loss: 0.3823\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3530 - val_loss: 0.3828\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3526 - val_loss: 0.3821\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3517 - val_loss: 0.3800\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3514 - val_loss: 0.3814\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3513 - val_loss: 0.3797\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3508 - val_loss: 0.3802\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3782\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3499 - val_loss: 0.3800\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3493 - val_loss: 0.3786\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3481 - val_loss: 0.3775\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3480 - val_loss: 0.3793\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3469 - val_loss: 0.3794\n",
      "121/121 [==============================] - 0s 466us/step - loss: 0.3694\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5364 - val_loss: 1.3813\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.9523 - val_loss: 0.7353\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.6844 - val_loss: 0.6425\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.6242 - val_loss: 0.6134\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5973 - val_loss: 0.5927\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.5765 - val_loss: 0.5732\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5588 - val_loss: 0.5589\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5432 - val_loss: 0.5455\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.5295 - val_loss: 0.5359\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5178 - val_loss: 0.5252\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5073 - val_loss: 0.5195\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4988 - val_loss: 0.5131\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4914 - val_loss: 0.5040\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4848 - val_loss: 0.4976\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4789 - val_loss: 0.4943\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4738 - val_loss: 0.4883\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4690 - val_loss: 0.4835\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4644 - val_loss: 0.4800\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4605 - val_loss: 0.4779\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4573 - val_loss: 0.4765\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4542 - val_loss: 0.4732\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4514 - val_loss: 0.4705\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4488 - val_loss: 0.4663\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4460 - val_loss: 0.4665\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4439 - val_loss: 0.4634\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4420 - val_loss: 0.4609\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4393 - val_loss: 0.4629\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4379 - val_loss: 0.4584\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4360 - val_loss: 0.4567\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4345 - val_loss: 0.4554\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4325 - val_loss: 0.4539\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4307 - val_loss: 0.4533\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4295 - val_loss: 0.4511\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4282 - val_loss: 0.4516\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4268 - val_loss: 0.4515\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4253 - val_loss: 0.4500\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4241 - val_loss: 0.4471\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4221 - val_loss: 0.4472\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4221 - val_loss: 0.4441\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4206 - val_loss: 0.4430\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4194 - val_loss: 0.4451\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4186 - val_loss: 0.4418\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4171 - val_loss: 0.4455\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 709us/step - loss: 0.4163 - val_loss: 0.4404\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.4151 - val_loss: 0.4413\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4139 - val_loss: 0.4369\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.4131 - val_loss: 0.4360\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4123 - val_loss: 0.4360\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.4110 - val_loss: 0.4349\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.4102 - val_loss: 0.4349\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4097 - val_loss: 0.4329\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4080 - val_loss: 0.4367\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4075 - val_loss: 0.4313\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4063 - val_loss: 0.4316\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4055 - val_loss: 0.4304\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4044 - val_loss: 0.4308\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4034 - val_loss: 0.4290\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.4026 - val_loss: 0.4284\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4017 - val_loss: 0.4305\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4009 - val_loss: 0.4271\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4003 - val_loss: 0.4265\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3995 - val_loss: 0.4256\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3983 - val_loss: 0.4237\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3974 - val_loss: 0.4258\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.3973 - val_loss: 0.4230\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3962 - val_loss: 0.4245\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.3953 - val_loss: 0.4230\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.3946 - val_loss: 0.4205\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3938 - val_loss: 0.4218\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3929 - val_loss: 0.4206\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3920 - val_loss: 0.4216\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3917 - val_loss: 0.4233\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3908 - val_loss: 0.4176\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3900 - val_loss: 0.4170\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3894 - val_loss: 0.4189\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3884 - val_loss: 0.4163\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.3878 - val_loss: 0.4161\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.3870 - val_loss: 0.4190\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3862 - val_loss: 0.4175\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3856 - val_loss: 0.4161\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3848 - val_loss: 0.4149\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3846 - val_loss: 0.4152\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3837 - val_loss: 0.4138\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3830 - val_loss: 0.4149\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3823 - val_loss: 0.4117\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3810 - val_loss: 0.4113\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3810 - val_loss: 0.4104\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3800 - val_loss: 0.4115\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3794 - val_loss: 0.4080\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3793 - val_loss: 0.4086\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3783 - val_loss: 0.4076\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3776 - val_loss: 0.4059\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3764 - val_loss: 0.4110\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.3765 - val_loss: 0.4078\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3752 - val_loss: 0.4060\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3751 - val_loss: 0.4044\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3744 - val_loss: 0.4064\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3738 - val_loss: 0.4048\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3732 - val_loss: 0.4093\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3724 - val_loss: 0.4054\n",
      "121/121 [==============================] - 0s 499us/step - loss: 0.3704\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8793 - val_loss: 0.8935\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.7359 - val_loss: 0.6737\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.6313 - val_loss: 0.6227\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 0.5859\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5483 - val_loss: 0.5612\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.5228 - val_loss: 0.5438\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5050 - val_loss: 0.5267\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4908 - val_loss: 0.5143\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4792 - val_loss: 0.5072\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4702 - val_loss: 0.4988\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4635 - val_loss: 0.4916\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4572 - val_loss: 0.4869\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4521 - val_loss: 0.4806\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4475 - val_loss: 0.4771\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.4440 - val_loss: 0.4730\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4401 - val_loss: 0.4701\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4365 - val_loss: 0.4673\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4343 - val_loss: 0.4629\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4315 - val_loss: 0.4617\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4286 - val_loss: 0.4602\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4262 - val_loss: 0.4557\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 684us/step - loss: 0.4238 - val_loss: 0.4533\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4206 - val_loss: 0.4570\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4194 - val_loss: 0.4487\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4172 - val_loss: 0.4480\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 0.4155 - val_loss: 0.4467\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4131 - val_loss: 0.4438\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.4115 - val_loss: 0.4414\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4095 - val_loss: 0.4402\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4078 - val_loss: 0.4380\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4060 - val_loss: 0.4369\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4047 - val_loss: 0.4348\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4026 - val_loss: 0.4336\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4014 - val_loss: 0.4322\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3994 - val_loss: 0.4307\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3982 - val_loss: 0.4295\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3968 - val_loss: 0.4278\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3952 - val_loss: 0.4263\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3938 - val_loss: 0.4273\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3928 - val_loss: 0.4241\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.3910 - val_loss: 0.4224\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3900 - val_loss: 0.4213\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3889 - val_loss: 0.4211\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3875 - val_loss: 0.4202\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3862 - val_loss: 0.4198\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3848 - val_loss: 0.4174\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3839 - val_loss: 0.4184\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3828 - val_loss: 0.4164\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3818 - val_loss: 0.4151\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3802 - val_loss: 0.4144\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3790 - val_loss: 0.4134\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3784 - val_loss: 0.4113\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3774 - val_loss: 0.4108\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3761 - val_loss: 0.4105\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3751 - val_loss: 0.4095\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3742 - val_loss: 0.4090\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3733 - val_loss: 0.4078\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3723 - val_loss: 0.4066\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3709 - val_loss: 0.4068\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3703 - val_loss: 0.4055\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3692 - val_loss: 0.4061\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3681 - val_loss: 0.4033\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3673 - val_loss: 0.4056\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3662 - val_loss: 0.4025\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3654 - val_loss: 0.4009\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.3645 - val_loss: 0.4001\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3638 - val_loss: 0.4003\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3628 - val_loss: 0.3988\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3619 - val_loss: 0.3988\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3610 - val_loss: 0.3973\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3596 - val_loss: 0.3973\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3597 - val_loss: 0.3967\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.3581 - val_loss: 0.3984\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3573 - val_loss: 0.3973\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3569 - val_loss: 0.3939\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3560 - val_loss: 0.3941\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3553 - val_loss: 0.3935\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3536 - val_loss: 0.3937\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3530 - val_loss: 0.3907\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3523 - val_loss: 0.3909\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3517 - val_loss: 0.3910\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3506 - val_loss: 0.3903\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3494 - val_loss: 0.3895\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3488 - val_loss: 0.3887\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3482 - val_loss: 0.3876\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3473 - val_loss: 0.3878\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3467 - val_loss: 0.3864\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3451 - val_loss: 0.3859\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.3445 - val_loss: 0.3856\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3440 - val_loss: 0.3857\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.3431 - val_loss: 0.3856\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3428 - val_loss: 0.3834\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3420 - val_loss: 0.3831\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3408 - val_loss: 0.3832\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3402 - val_loss: 0.3815\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3391 - val_loss: 0.3828\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3388 - val_loss: 0.3803\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.3383 - val_loss: 0.3800\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3373 - val_loss: 0.3793\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3364 - val_loss: 0.3802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/121 [..............................] - ETA: 0s - loss: 0.7255WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 503us/step - loss: 0.3810\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.8115 - val_loss: 4.3922\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 4.3093 - val_loss: 3.3541\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 3.2601 - val_loss: 2.6177\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 2.5237 - val_loss: 2.0927\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 2.0035 - val_loss: 1.7155\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 648us/step - loss: 1.6355 - val_loss: 1.4438\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 1.3731 - val_loss: 1.2472\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 1.1852 - val_loss: 1.1036\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 1.0500 - val_loss: 0.9987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.9523 - val_loss: 0.9217\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.8811 - val_loss: 0.8640\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.8286 - val_loss: 0.8204\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.7895 - val_loss: 0.7875\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.7601 - val_loss: 0.7617\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.7376 - val_loss: 0.7415\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.7200 - val_loss: 0.7254\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.7060 - val_loss: 0.7123\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.6947 - val_loss: 0.7014\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.6853 - val_loss: 0.6920\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6774 - val_loss: 0.6838\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.6704 - val_loss: 0.6768\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.6643 - val_loss: 0.6702\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 630us/step - loss: 0.6588 - val_loss: 0.6642\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.6537 - val_loss: 0.6588\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.6490 - val_loss: 0.6538\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.6446 - val_loss: 0.6491\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.6404 - val_loss: 0.6446\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.6365 - val_loss: 0.6402\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.649 - 0s 762us/step - loss: 0.6327 - val_loss: 0.6361\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.6291 - val_loss: 0.6322\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.6256 - val_loss: 0.6284\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.6223 - val_loss: 0.6248\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.6190 - val_loss: 0.6214\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.6159 - val_loss: 0.6180\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.6129 - val_loss: 0.6148\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.6100 - val_loss: 0.6119\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.6071 - val_loss: 0.6089\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.6044 - val_loss: 0.6061\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.6017 - val_loss: 0.6034\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5991 - val_loss: 0.6008\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.5966 - val_loss: 0.5982\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.5942 - val_loss: 0.5958\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.5919 - val_loss: 0.5935\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.5896 - val_loss: 0.5913\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5874 - val_loss: 0.5891\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5852 - val_loss: 0.5871\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5832 - val_loss: 0.5851\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.5811 - val_loss: 0.5832\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.5792 - val_loss: 0.5815\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5773 - val_loss: 0.5797\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.5754 - val_loss: 0.5781\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5736 - val_loss: 0.5765\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.5719 - val_loss: 0.5750\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5702 - val_loss: 0.5735\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5686 - val_loss: 0.5721\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5670 - val_loss: 0.5708\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.5655 - val_loss: 0.5695\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5640 - val_loss: 0.5683\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.5626 - val_loss: 0.5671\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.5612 - val_loss: 0.5660\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5598 - val_loss: 0.5649\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5585 - val_loss: 0.5639\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5572 - val_loss: 0.5629\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5560 - val_loss: 0.5620\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5548 - val_loss: 0.5611\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5536 - val_loss: 0.5603\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.5525 - val_loss: 0.5595\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5514 - val_loss: 0.5587\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.5503 - val_loss: 0.5580\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 640us/step - loss: 0.5493 - val_loss: 0.5574\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5483 - val_loss: 0.5567\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5473 - val_loss: 0.5561\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5464 - val_loss: 0.5555\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.5455 - val_loss: 0.5549\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.5446 - val_loss: 0.5544\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 758us/step - loss: 0.5437 - val_loss: 0.5539\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5429 - val_loss: 0.5535\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5421 - val_loss: 0.5530\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.5413 - val_loss: 0.5526\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.5405 - val_loss: 0.5522\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.5398 - val_loss: 0.5519\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.5391 - val_loss: 0.5516\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5384 - val_loss: 0.5513\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.5377 - val_loss: 0.5509\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5371 - val_loss: 0.5507\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5364 - val_loss: 0.5505\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5358 - val_loss: 0.5502\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5352 - val_loss: 0.5500\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.5346 - val_loss: 0.5497\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.5341 - val_loss: 0.5496\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.5335 - val_loss: 0.5494\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.5330 - val_loss: 0.5493\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.5325 - val_loss: 0.5491\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.5320 - val_loss: 0.5490\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.5315 - val_loss: 0.5489\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5311 - val_loss: 0.5489\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.5306 - val_loss: 0.5487\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5302 - val_loss: 0.5487\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5297 - val_loss: 0.5486\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.5293 - val_loss: 0.5486\n",
      "121/121 [==============================] - 0s 530us/step - loss: 0.5244\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.3731 - val_loss: 4.8971\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 4.0189 - val_loss: 3.6889\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 694us/step - loss: 3.0516 - val_loss: 2.8246\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 2.3600 - val_loss: 2.2058\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 1.8628 - val_loss: 1.7598\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 1.5043 - val_loss: 1.4377\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 1.2447 - val_loss: 1.2040\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 1.0563 - val_loss: 1.0332\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.9192 - val_loss: 0.9092\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.8194 - val_loss: 0.8186\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.7464 - val_loss: 0.7522\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 620us/step - loss: 0.6930 - val_loss: 0.7038\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.6538 - val_loss: 0.6675\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.6248 - val_loss: 0.6406\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.6034 - val_loss: 0.6210\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5875 - val_loss: 0.6062\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5757 - val_loss: 0.5952\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5668 - val_loss: 0.5868\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5601 - val_loss: 0.5805\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.5550 - val_loss: 0.5756\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.5511 - val_loss: 0.5720\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.5481 - val_loss: 0.5693\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5457 - val_loss: 0.5671\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5439 - val_loss: 0.5653\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.5424 - val_loss: 0.5639\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5412 - val_loss: 0.5628\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5402 - val_loss: 0.5620\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5393 - val_loss: 0.5614\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.5386 - val_loss: 0.5609\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5379 - val_loss: 0.5603\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.5374 - val_loss: 0.5601\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5369 - val_loss: 0.5597\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5364 - val_loss: 0.5595\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5360 - val_loss: 0.5594\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5356 - val_loss: 0.5594\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.5353 - val_loss: 0.5593\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5349 - val_loss: 0.5590\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5346 - val_loss: 0.5588\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5343 - val_loss: 0.5587\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5340 - val_loss: 0.5586\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.5338 - val_loss: 0.5588\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.5335 - val_loss: 0.5588\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.5332 - val_loss: 0.5587\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5330 - val_loss: 0.5589\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5328 - val_loss: 0.5588\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.5326 - val_loss: 0.5589\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5323 - val_loss: 0.5590\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.5321 - val_loss: 0.5589\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.5319 - val_loss: 0.5591\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.5317 - val_loss: 0.5591\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.5953WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 449us/step - loss: 0.5064\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1451 - val_loss: 4.4363\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 3.9555 - val_loss: 3.4358\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 3.0921 - val_loss: 2.7113\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 2.4643 - val_loss: 2.1862\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 665us/step - loss: 2.0066 - val_loss: 1.8047\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 1.6718 - val_loss: 1.5274\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 1.4262 - val_loss: 1.3244\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 1.2449 - val_loss: 1.1757\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 1.1106 - val_loss: 1.0666\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 1.0105 - val_loss: 0.9864\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.9354 - val_loss: 0.9267\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.8784 - val_loss: 0.8820\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.8347 - val_loss: 0.8483\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.8009 - val_loss: 0.8229\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.7745 - val_loss: 0.8035\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.7534 - val_loss: 0.7883\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.7363 - val_loss: 0.7760\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.7224 - val_loss: 0.7662\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.7107 - val_loss: 0.7583\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.7008 - val_loss: 0.7516\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6922 - val_loss: 0.7458\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.6848 - val_loss: 0.7408\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.6781 - val_loss: 0.7363\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6722 - val_loss: 0.7323\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6668 - val_loss: 0.7286\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.6619 - val_loss: 0.7252\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.6573 - val_loss: 0.7220\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.6531 - val_loss: 0.7190\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.6492 - val_loss: 0.7161\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.6455 - val_loss: 0.7134\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.6420 - val_loss: 0.7108\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6387 - val_loss: 0.7082\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.6356 - val_loss: 0.7057\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.6326 - val_loss: 0.7033\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.6298 - val_loss: 0.7009\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.6270 - val_loss: 0.6986\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.6244 - val_loss: 0.6963\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.6220 - val_loss: 0.6941\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.6195 - val_loss: 0.6920\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.6172 - val_loss: 0.6898\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.6150 - val_loss: 0.6878\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.6129 - val_loss: 0.6858\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6108 - val_loss: 0.6839\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6088 - val_loss: 0.6819\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.6068 - val_loss: 0.6800\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.6050 - val_loss: 0.6782\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.6031 - val_loss: 0.6763\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.6013 - val_loss: 0.6745\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.5996 - val_loss: 0.6728\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.5980 - val_loss: 0.6711\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.5963 - val_loss: 0.6694\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5947 - val_loss: 0.6677\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5932 - val_loss: 0.6660\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5917 - val_loss: 0.6644\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5902 - val_loss: 0.6629\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5888 - val_loss: 0.6613\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5874 - val_loss: 0.6598\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5860 - val_loss: 0.6583\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5847 - val_loss: 0.6569\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5834 - val_loss: 0.6554\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5821 - val_loss: 0.6540\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.5808 - val_loss: 0.6526\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5796 - val_loss: 0.6512\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5784 - val_loss: 0.6498\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5772 - val_loss: 0.6485\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5761 - val_loss: 0.6472\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.5749 - val_loss: 0.6459\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.5738 - val_loss: 0.6447\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.5727 - val_loss: 0.6434\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.5717 - val_loss: 0.6422\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.5706 - val_loss: 0.6410\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5696 - val_loss: 0.6399\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5686 - val_loss: 0.6387\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5676 - val_loss: 0.6376\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.5666 - val_loss: 0.6364\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5657 - val_loss: 0.6353\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.5648 - val_loss: 0.6342\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.5638 - val_loss: 0.6331\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 704us/step - loss: 0.5629 - val_loss: 0.6321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5621 - val_loss: 0.6310\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5612 - val_loss: 0.6300\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5603 - val_loss: 0.6291\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.5595 - val_loss: 0.6281\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.5587 - val_loss: 0.6271\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.5579 - val_loss: 0.6261\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.5571 - val_loss: 0.6252\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.5563 - val_loss: 0.6243\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.5555 - val_loss: 0.6234\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.5548 - val_loss: 0.6225\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5540 - val_loss: 0.6216\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.5533 - val_loss: 0.6207\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5526 - val_loss: 0.6198\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5519 - val_loss: 0.6191\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.5512 - val_loss: 0.6182\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5505 - val_loss: 0.6173\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5498 - val_loss: 0.6164\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.5492 - val_loss: 0.6156\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5485 - val_loss: 0.6149\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.5479 - val_loss: 0.6141\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5473 - val_loss: 0.6132\n",
      "121/121 [==============================] - 0s 451us/step - loss: 0.5770\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9504 - val_loss: 0.5720\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5087 - val_loss: 0.4871\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4520 - val_loss: 0.4638\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.4312 - val_loss: 0.4482\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4136 - val_loss: 0.4392\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.4060 - val_loss: 0.4475\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3984 - val_loss: 0.4186\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3933 - val_loss: 0.4135\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3870 - val_loss: 0.4073\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3845 - val_loss: 0.4086\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4026\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3797 - val_loss: 0.3997\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3764 - val_loss: 0.4080\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3717 - val_loss: 0.3957\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.3687 - val_loss: 0.3882\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3658 - val_loss: 0.3910\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3626 - val_loss: 0.3954\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3606 - val_loss: 0.3961\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3607 - val_loss: 0.3854\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3555 - val_loss: 0.3884\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3576 - val_loss: 0.3866\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3530 - val_loss: 0.3803\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3549 - val_loss: 0.3736\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3498 - val_loss: 0.3835\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.3501 - val_loss: 0.3738\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3494 - val_loss: 0.3753\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3487 - val_loss: 0.3814\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3445 - val_loss: 0.3755\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3425 - val_loss: 0.3870\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3432 - val_loss: 0.3727\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3418 - val_loss: 0.3676\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.3394 - val_loss: 0.3847\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3391 - val_loss: 0.3770\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.3388 - val_loss: 0.3636\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3356 - val_loss: 0.3736\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3345 - val_loss: 0.3745\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3336 - val_loss: 0.3601\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3307 - val_loss: 0.3587\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3318 - val_loss: 0.3957\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3326 - val_loss: 0.3574\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.3294 - val_loss: 0.3511\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.3363 - val_loss: 0.3519\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3267 - val_loss: 0.3616\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3273 - val_loss: 0.3462\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3241 - val_loss: 0.3591\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3251 - val_loss: 0.3465\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3222 - val_loss: 0.3490\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3233 - val_loss: 0.3602\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3214 - val_loss: 0.3596\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.3195 - val_loss: 0.3715\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3201 - val_loss: 0.3496\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3200 - val_loss: 0.3485\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3184 - val_loss: 0.3530\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3184 - val_loss: 0.3443\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3154 - val_loss: 0.3702\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3172 - val_loss: 0.3354\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3132 - val_loss: 0.3507\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 664us/step - loss: 0.3145 - val_loss: 0.3407\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3138 - val_loss: 0.3420\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3132 - val_loss: 0.3321\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3128 - val_loss: 0.3548\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3120 - val_loss: 0.3510\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3121 - val_loss: 0.3430\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3087 - val_loss: 0.3330\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3098 - val_loss: 0.3331\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3089 - val_loss: 0.3329\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3071 - val_loss: 0.3453\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3075 - val_loss: 0.3541\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3070 - val_loss: 0.3364\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3082 - val_loss: 0.3342\n",
      "121/121 [==============================] - 0s 437us/step - loss: 0.3338\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1505 - val_loss: 0.5831\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5551 - val_loss: 0.4937\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4731 - val_loss: 0.4662\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4489 - val_loss: 0.4540\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4359 - val_loss: 0.4502\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4259 - val_loss: 0.4491\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.4184 - val_loss: 0.4492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.4140 - val_loss: 0.4287\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4070 - val_loss: 0.4268\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.4018 - val_loss: 0.4237\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3955 - val_loss: 0.4132\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3917 - val_loss: 0.4101\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3857 - val_loss: 0.4044\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3830 - val_loss: 0.4208\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3792 - val_loss: 0.4004\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3754 - val_loss: 0.3882\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.3702 - val_loss: 0.3926\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3677 - val_loss: 0.3887\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3633 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3608 - val_loss: 0.4137\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3589 - val_loss: 0.3788\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3545 - val_loss: 0.3749\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3551 - val_loss: 0.3701\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3505 - val_loss: 0.3710\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 662us/step - loss: 0.3497 - val_loss: 0.3819\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3496 - val_loss: 0.3863\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3463 - val_loss: 0.3731\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3447 - val_loss: 0.3701\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3430 - val_loss: 0.3670\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3412 - val_loss: 0.3592\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3384 - val_loss: 0.3630\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3377 - val_loss: 0.3559\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.3353 - val_loss: 0.3724\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.3351 - val_loss: 0.3835\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3330 - val_loss: 0.3639\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.3316 - val_loss: 0.3767\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.3311 - val_loss: 0.3486\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3278 - val_loss: 0.3656\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3292 - val_loss: 0.3676\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3252 - val_loss: 0.3548\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3259 - val_loss: 0.4067\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3245 - val_loss: 0.3892\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3275 - val_loss: 0.3537\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3236 - val_loss: 0.3638\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.3230 - val_loss: 0.3471\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.3213 - val_loss: 0.3765\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3196 - val_loss: 0.3453\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.3200 - val_loss: 0.3672\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3176 - val_loss: 0.3595\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3153 - val_loss: 0.3455\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3171 - val_loss: 0.3719\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.3149 - val_loss: 0.3453\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.3134 - val_loss: 0.3736\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3132 - val_loss: 0.3601\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3123 - val_loss: 0.3377\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3131 - val_loss: 0.3716\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3129 - val_loss: 0.3362\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3104 - val_loss: 0.3360\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3100 - val_loss: 0.3371\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3088 - val_loss: 0.3484\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.3093 - val_loss: 0.3391\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.3381\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3053 - val_loss: 0.3331\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.3040 - val_loss: 0.3563\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3034 - val_loss: 0.3368\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 696us/step - loss: 0.3048 - val_loss: 0.3291\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3043 - val_loss: 0.3257\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3014 - val_loss: 0.3266\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3016 - val_loss: 0.3241\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3018 - val_loss: 0.3412\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3020 - val_loss: 0.3260\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3034 - val_loss: 0.3335\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.2974 - val_loss: 0.3429\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.2986 - val_loss: 0.3358\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2982 - val_loss: 0.3259\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.2988 - val_loss: 0.3242\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2980 - val_loss: 0.3189\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.2972 - val_loss: 0.3154\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.2972 - val_loss: 0.3340\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.2933 - val_loss: 0.3347\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.2939 - val_loss: 0.3153\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2966 - val_loss: 0.3227\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.2935 - val_loss: 0.3271\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2948 - val_loss: 0.3361\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.2926 - val_loss: 0.3149\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.2946 - val_loss: 0.3155\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.2905 - val_loss: 0.3300\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.2926 - val_loss: 0.3121\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.2932 - val_loss: 0.3184\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2916 - val_loss: 0.3366\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2906 - val_loss: 0.3190\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.2917 - val_loss: 0.3327\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.2897 - val_loss: 0.3185\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2916 - val_loss: 0.3135\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.2922 - val_loss: 0.3258\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.2905 - val_loss: 0.3273\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.2891 - val_loss: 0.3106\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.2903 - val_loss: 0.3413\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.2880 - val_loss: 0.3281\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.2876 - val_loss: 0.3181\n",
      "121/121 [==============================] - 0s 503us/step - loss: 0.2912\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8724 - val_loss: 0.5610\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.5082 - val_loss: 0.5240\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4594 - val_loss: 0.4650\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4378 - val_loss: 0.4874\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4283 - val_loss: 0.4564\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4225 - val_loss: 0.4419\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.4121 - val_loss: 0.4423\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.412 - 0s 788us/step - loss: 0.4061 - val_loss: 0.4308\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3987 - val_loss: 0.4257\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3959 - val_loss: 0.4204\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.3892 - val_loss: 0.4244\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.3870 - val_loss: 0.4162\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3823 - val_loss: 0.4162\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3802 - val_loss: 0.4200\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.3731 - val_loss: 0.4097\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3687 - val_loss: 0.3980\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3670 - val_loss: 0.4047\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3662 - val_loss: 0.3938\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3637 - val_loss: 0.3899\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3620 - val_loss: 0.3963\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3571 - val_loss: 0.3920\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3555 - val_loss: 0.4163\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3544 - val_loss: 0.3966\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3508 - val_loss: 0.4054\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3548 - val_loss: 0.3843\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.3476 - val_loss: 0.3759\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3492 - val_loss: 0.3820\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3415 - val_loss: 0.3850\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3413 - val_loss: 0.3795\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.3379 - val_loss: 0.4073\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.3393 - val_loss: 0.3760\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3341 - val_loss: 0.3779\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3332 - val_loss: 0.3727\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3339 - val_loss: 0.3819\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.3303 - val_loss: 0.3797\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3291 - val_loss: 0.3771\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3252 - val_loss: 0.3620\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3258 - val_loss: 0.3711\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3255 - val_loss: 0.3624\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3246 - val_loss: 0.3667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3224 - val_loss: 0.3576\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3209 - val_loss: 0.3615\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3199 - val_loss: 0.3505\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 761us/step - loss: 0.3199 - val_loss: 0.3563\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3163 - val_loss: 0.3542\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3186 - val_loss: 0.3539\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3169 - val_loss: 0.3458\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3155 - val_loss: 0.3469\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3168 - val_loss: 0.3482\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3177 - val_loss: 0.3646\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3121 - val_loss: 0.3514\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3115 - val_loss: 0.3509\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3097 - val_loss: 0.3408\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3077 - val_loss: 0.3386\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3079 - val_loss: 0.3494\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3066 - val_loss: 0.3408\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3060 - val_loss: 0.3321\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3043 - val_loss: 0.3455\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3017 - val_loss: 0.3445\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3033 - val_loss: 0.3376\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3024 - val_loss: 0.3402\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3017 - val_loss: 0.3461\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3013 - val_loss: 0.3374\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.2994 - val_loss: 0.3280\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.2993 - val_loss: 0.3305\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3027 - val_loss: 0.3350\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.2970 - val_loss: 0.3430\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3383\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.2986 - val_loss: 0.3363\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.2948 - val_loss: 0.3371\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.2950 - val_loss: 0.3695\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.2994 - val_loss: 0.3312\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.2953 - val_loss: 0.3307\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.2934 - val_loss: 0.3362\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.3632\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8369 - val_loss: 0.5573\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.5250 - val_loss: 0.5068\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.4805 - val_loss: 0.4839\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4590 - val_loss: 0.4686\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4464 - val_loss: 0.4621\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4397 - val_loss: 0.4683\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4318 - val_loss: 0.4483\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4274 - val_loss: 0.4512\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4221 - val_loss: 0.4501\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4183 - val_loss: 0.4502\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4147 - val_loss: 0.4399\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4120 - val_loss: 0.4412\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4096 - val_loss: 0.4314\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4064 - val_loss: 0.4309\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.4042 - val_loss: 0.4531\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4013 - val_loss: 0.4240\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3991 - val_loss: 0.4280\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3975 - val_loss: 0.4298\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3955 - val_loss: 0.4285\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3956 - val_loss: 0.4258\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.3941 - val_loss: 0.4212\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3914 - val_loss: 0.4174\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3886 - val_loss: 0.4131\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3884 - val_loss: 0.4084\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3877 - val_loss: 0.4068\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3858 - val_loss: 0.4084\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3848 - val_loss: 0.4108\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3841 - val_loss: 0.4099\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3807 - val_loss: 0.4102\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3809 - val_loss: 0.4019\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3784 - val_loss: 0.4071\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3803 - val_loss: 0.4003\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3771 - val_loss: 0.4167\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3766 - val_loss: 0.4004\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3729 - val_loss: 0.3972\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3736 - val_loss: 0.3963\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3715 - val_loss: 0.3954\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3699 - val_loss: 0.3884\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3692 - val_loss: 0.3947\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.3673 - val_loss: 0.3920\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.3669 - val_loss: 0.3966\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3655 - val_loss: 0.4017\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3638 - val_loss: 0.3886\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3627 - val_loss: 0.3880\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3615 - val_loss: 0.3818\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3597 - val_loss: 0.3881\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3604 - val_loss: 0.3897\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 664us/step - loss: 0.3603 - val_loss: 0.3878\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3588 - val_loss: 0.3750\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3557 - val_loss: 0.3775\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.3590 - val_loss: 0.3792\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3553 - val_loss: 0.4089\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3549 - val_loss: 0.3792\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3543 - val_loss: 0.3753\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3530 - val_loss: 0.3712\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.3518 - val_loss: 0.3777\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3509 - val_loss: 0.3917\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3509 - val_loss: 0.3706\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3504 - val_loss: 0.3697\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3513 - val_loss: 0.3948\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3755\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3504 - val_loss: 0.3733\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3469 - val_loss: 0.3822\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.3510 - val_loss: 0.3615\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.3475 - val_loss: 0.3669\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3473 - val_loss: 0.3781\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3473 - val_loss: 0.3593\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.3455 - val_loss: 0.3640\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.3445 - val_loss: 0.3626\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3444 - val_loss: 0.3827\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3439 - val_loss: 0.3944\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3557 - val_loss: 0.3941\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3444 - val_loss: 0.3773\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.3443 - val_loss: 0.3632\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3424 - val_loss: 0.3879\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 620us/step - loss: 0.3522 - val_loss: 0.3927\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.3418 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 453us/step - loss: 0.3598\n",
      "Epoch 1/100\n",
      "189/242 [======================>.......] - ETA: 0s - loss: 0.8096WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7847 - val_loss: 0.5626\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.5122 - val_loss: 0.5010\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4807 - val_loss: 0.4904\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4684 - val_loss: 0.4745\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4589 - val_loss: 0.4602\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4689 - val_loss: 0.4721\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 669us/step - loss: 0.4855 - val_loss: 0.4563\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4505 - val_loss: 0.4507\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4461 - val_loss: 0.4799\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.4480 - val_loss: 0.4556\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.4542 - val_loss: 0.4557\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4375 - val_loss: 0.4378\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4378 - val_loss: 0.4503\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4362 - val_loss: 0.4472\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4369 - val_loss: 0.4421\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4299 - val_loss: 0.4387\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.4320 - val_loss: 0.4305\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4261 - val_loss: 0.4235\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4201 - val_loss: 0.4267\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4513 - val_loss: 0.4234\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 634us/step - loss: 0.4126 - val_loss: 0.4419\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4090 - val_loss: 0.4157\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4081 - val_loss: 0.4441\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4059 - val_loss: 0.4132\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4204 - val_loss: 0.4357\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4019 - val_loss: 0.4203\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.401 - 0s 635us/step - loss: 0.4025 - val_loss: 0.4062\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4006 - val_loss: 0.4071\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3989 - val_loss: 0.4130\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.3952 - val_loss: 0.4157\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3927 - val_loss: 0.4186\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3905 - val_loss: 0.3988\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3902 - val_loss: 0.4055\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3992 - val_loss: 0.4006\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3915 - val_loss: 0.4032\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.5114\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.3831 - val_loss: 0.3978\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3841 - val_loss: 0.4049\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3983 - val_loss: 0.3958\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3936 - val_loss: 0.4024\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3932 - val_loss: 0.4304\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3784 - val_loss: 0.4054\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3796 - val_loss: 0.4444\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3778 - val_loss: 0.4114\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3761 - val_loss: 0.5362\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3777 - val_loss: 0.3996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3757 - val_loss: 0.4018\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.3724 - val_loss: 0.4936\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.3855 - val_loss: 0.4101\n",
      "121/121 [==============================] - 0s 458us/step - loss: 0.3587\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 6.1989WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8601 - val_loss: 0.5977\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5269 - val_loss: 0.5311\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4879 - val_loss: 0.4959\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4674 - val_loss: 0.5092\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4537 - val_loss: 0.4662\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4504 - val_loss: 0.4681\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4389 - val_loss: 0.4542\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4346 - val_loss: 0.4515\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4303 - val_loss: 0.4579\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4252 - val_loss: 0.4533\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4195 - val_loss: 0.4393\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4164 - val_loss: 0.4387\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4112 - val_loss: 0.4339\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4114 - val_loss: 0.4326\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4071 - val_loss: 0.4296\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4014 - val_loss: 0.4245\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4038 - val_loss: 0.4212\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3968 - val_loss: 0.4468\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.3977 - val_loss: 0.4181\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3940 - val_loss: 0.4269\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3904 - val_loss: 0.4142\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3886 - val_loss: 0.4089\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3882 - val_loss: 0.4097\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3832 - val_loss: 0.4128\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3850 - val_loss: 0.4337\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.3823 - val_loss: 0.4153\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3807 - val_loss: 0.4067\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3857 - val_loss: 0.4179\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3925 - val_loss: 0.4098\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3767 - val_loss: 0.3995\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3789 - val_loss: 0.4042\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3751 - val_loss: 0.3944\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3835 - val_loss: 0.4261\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3723 - val_loss: 0.4004\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3683 - val_loss: 0.3981\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3691 - val_loss: 0.3920\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3655 - val_loss: 0.3977\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.3693 - val_loss: 0.3964\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.3665 - val_loss: 0.4170\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3646 - val_loss: 0.4248\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3755 - val_loss: 0.3882\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3616 - val_loss: 0.3885\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3631 - val_loss: 0.3966\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3640 - val_loss: 0.3979\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3788 - val_loss: 0.4285\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3889 - val_loss: 0.4033\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3634 - val_loss: 0.3887\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3590 - val_loss: 0.3925\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3581 - val_loss: 0.3815\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3615 - val_loss: 0.3930\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.3595 - val_loss: 0.3899\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3589 - val_loss: 0.3836\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3580 - val_loss: 0.3833\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3556 - val_loss: 0.3820\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3638 - val_loss: 0.3856\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.3616 - val_loss: 0.3858\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3559 - val_loss: 0.3842\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3561 - val_loss: 0.3727\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.3556 - val_loss: 0.3765\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3546 - val_loss: 0.5760\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3526 - val_loss: 0.4201\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3536 - val_loss: 0.4251\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3576 - val_loss: 0.3772\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3516 - val_loss: 0.3868\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 645us/step - loss: 0.3552 - val_loss: 0.3736\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.3503 - val_loss: 0.3902\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3513 - val_loss: 0.6503\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3487 - val_loss: 0.5105\n",
      "121/121 [==============================] - 0s 506us/step - loss: 0.3957\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 6.1004WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5538 - val_loss: 0.7088\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.6475 - val_loss: 0.5952\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.5568 - val_loss: 0.5430\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.5075 - val_loss: 0.5099\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.4740 - val_loss: 0.4787\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4487 - val_loss: 0.4626\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4325 - val_loss: 0.4486\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4197 - val_loss: 0.4372\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4111 - val_loss: 0.4288\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4032 - val_loss: 0.4248\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3976 - val_loss: 0.4260\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.3921 - val_loss: 0.4194\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3869 - val_loss: 0.4235\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3841 - val_loss: 0.4130\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3809 - val_loss: 0.4080\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3772 - val_loss: 0.4068\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3750 - val_loss: 0.4040\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3719 - val_loss: 0.4013\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3706 - val_loss: 0.4025\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3674 - val_loss: 0.4011\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3654 - val_loss: 0.3924\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3640 - val_loss: 0.3917\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3616 - val_loss: 0.3922\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3602 - val_loss: 0.3888\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3580 - val_loss: 0.3908\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3566 - val_loss: 0.3961\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3549 - val_loss: 0.3924\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3532 - val_loss: 0.3832\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3499 - val_loss: 0.3821\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3478 - val_loss: 0.3788\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3466 - val_loss: 0.3803\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3455 - val_loss: 0.3862\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3438 - val_loss: 0.3823\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3412 - val_loss: 0.3723\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3410 - val_loss: 0.3710\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.3748\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3671\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.3874\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.3360 - val_loss: 0.3660\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3728\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3334 - val_loss: 0.3696\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3322 - val_loss: 0.3641\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3290 - val_loss: 0.3618\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3284 - val_loss: 0.3589\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3259 - val_loss: 0.3765\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3278 - val_loss: 0.3621\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3264 - val_loss: 0.3620\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3279 - val_loss: 0.3536\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3250 - val_loss: 0.3742\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3238 - val_loss: 0.3523\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3222 - val_loss: 0.3579\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3181 - val_loss: 0.3516\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3177 - val_loss: 0.3550\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3168 - val_loss: 0.3516\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3135 - val_loss: 0.3582\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3136 - val_loss: 0.3533\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.3146 - val_loss: 0.3464\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3118 - val_loss: 0.3523\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.3113 - val_loss: 0.3450\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3093 - val_loss: 0.3474\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3085 - val_loss: 0.3537\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3064 - val_loss: 0.3594\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3085 - val_loss: 0.3393\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3063 - val_loss: 0.3444\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3043 - val_loss: 0.3456\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3043 - val_loss: 0.3479\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3040 - val_loss: 0.3413\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3026 - val_loss: 0.3395\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3403\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3017 - val_loss: 0.3547\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3457\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.3381\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.2998 - val_loss: 0.3447\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3015 - val_loss: 0.3426\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3048 - val_loss: 0.3364\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2974 - val_loss: 0.3490\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.2970 - val_loss: 0.3410\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.2982 - val_loss: 0.3368\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.2949 - val_loss: 0.3345\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 778us/step - loss: 0.2961 - val_loss: 0.3402\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2961 - val_loss: 0.3377\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.2946 - val_loss: 0.3463\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2937 - val_loss: 0.3399\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.2962 - val_loss: 0.3273\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2926 - val_loss: 0.3357\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.2939 - val_loss: 0.3309\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.2922 - val_loss: 0.3345\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.2932 - val_loss: 0.3416\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.2918 - val_loss: 0.3341\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.2907 - val_loss: 0.3338\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.2888 - val_loss: 0.3305\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.2896 - val_loss: 0.3322\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2918 - val_loss: 0.3331\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.2943 - val_loss: 0.3259\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.2878 - val_loss: 0.3303\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.2894 - val_loss: 0.3451\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.2871 - val_loss: 0.3300\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.2862 - val_loss: 0.3260\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2874 - val_loss: 0.3258\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.2862 - val_loss: 0.3235\n",
      "121/121 [==============================] - 0s 522us/step - loss: 0.3104\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6004 - val_loss: 0.7205\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.6747 - val_loss: 0.6287\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.6043 - val_loss: 0.5809\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.5621 - val_loss: 0.5482\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.5295 - val_loss: 0.5253\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5060 - val_loss: 0.4988\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4854 - val_loss: 0.4857\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4687 - val_loss: 0.4735\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4576 - val_loss: 0.4683\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4449 - val_loss: 0.4547\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4375 - val_loss: 0.4503\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4291 - val_loss: 0.4432\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4232 - val_loss: 0.4362\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4181 - val_loss: 0.4331\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4130 - val_loss: 0.4283\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4098 - val_loss: 0.4307\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4073 - val_loss: 0.4240\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4024 - val_loss: 0.4243\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.4006 - val_loss: 0.4172\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3986 - val_loss: 0.4152\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3943 - val_loss: 0.4153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3913 - val_loss: 0.4082\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3885 - val_loss: 0.4066\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3876 - val_loss: 0.4055\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3897 - val_loss: 0.4039\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3826 - val_loss: 0.4044\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3821 - val_loss: 0.4014\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3817 - val_loss: 0.4047\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3769 - val_loss: 0.3966\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.3763 - val_loss: 0.3970\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3738 - val_loss: 0.3953\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3724 - val_loss: 0.3963\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3811 - val_loss: 0.3883\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3671 - val_loss: 0.3860\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3649 - val_loss: 0.3869\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3636 - val_loss: 0.3842\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.3617 - val_loss: 0.3847\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3593 - val_loss: 0.3854\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3600 - val_loss: 0.3801\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3576 - val_loss: 0.3812\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3563 - val_loss: 0.3822\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3536 - val_loss: 0.3759\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3512 - val_loss: 0.3770\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3503 - val_loss: 0.3716\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3730\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3481 - val_loss: 0.3727\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3463 - val_loss: 0.3672\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3446 - val_loss: 0.3689\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3431 - val_loss: 0.3691\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3412 - val_loss: 0.3701\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.3387 - val_loss: 0.3641\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 712us/step - loss: 0.3377 - val_loss: 0.3628\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.3379 - val_loss: 0.3604\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3368 - val_loss: 0.3611\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.3335 - val_loss: 0.3565\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3322 - val_loss: 0.3584\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 771us/step - loss: 0.3303 - val_loss: 0.3568\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3304 - val_loss: 0.3553\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3284 - val_loss: 0.3563\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3259 - val_loss: 0.3530\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3268 - val_loss: 0.3546\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3365 - val_loss: 0.3510\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3244 - val_loss: 0.3503\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3210 - val_loss: 0.3505\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3217 - val_loss: 0.3521\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.3237 - val_loss: 0.3460\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.3206 - val_loss: 0.3471\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3170 - val_loss: 0.3485\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3175 - val_loss: 0.3515\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3174 - val_loss: 0.3425\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3140 - val_loss: 0.3471\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3144 - val_loss: 0.3471\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3115 - val_loss: 0.3427\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3121 - val_loss: 0.3432\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3103 - val_loss: 0.3481\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3112 - val_loss: 0.3416\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3083 - val_loss: 0.3476\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3096 - val_loss: 0.3449\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.3091 - val_loss: 0.3426\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3385\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3049 - val_loss: 0.3401\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3064 - val_loss: 0.3401\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3057 - val_loss: 0.3391\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3215 - val_loss: 0.3376\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.3020 - val_loss: 0.3413\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3000 - val_loss: 0.3387\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.3014 - val_loss: 0.3361\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.2993 - val_loss: 0.3411\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.2993 - val_loss: 0.3436\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.2993 - val_loss: 0.3387\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.2961 - val_loss: 0.3375\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2975 - val_loss: 0.3419\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.2972 - val_loss: 0.3386\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.2955 - val_loss: 0.3452\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.2969 - val_loss: 0.3381\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.2944 - val_loss: 0.3345\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.2936 - val_loss: 0.3317\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.2924 - val_loss: 0.3541\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.2936 - val_loss: 0.3433\n",
      "121/121 [==============================] - 0s 487us/step - loss: 0.3083\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2472 - val_loss: 0.7263\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.6525 - val_loss: 0.6214\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.5661 - val_loss: 0.5667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.5125 - val_loss: 0.5223\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4758 - val_loss: 0.4946\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4503 - val_loss: 0.4763\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4333 - val_loss: 0.4604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4204 - val_loss: 0.4511\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4112 - val_loss: 0.4410\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4025 - val_loss: 0.4323\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3970 - val_loss: 0.4273\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3914 - val_loss: 0.4255\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3853 - val_loss: 0.4167\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3820 - val_loss: 0.4110\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3775 - val_loss: 0.4085\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3738 - val_loss: 0.4071\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3702 - val_loss: 0.4058\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.3674 - val_loss: 0.4021\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3648 - val_loss: 0.3982\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3610 - val_loss: 0.3969\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3591 - val_loss: 0.3987\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3559 - val_loss: 0.3931\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3524 - val_loss: 0.3897\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3515 - val_loss: 0.3922\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3486 - val_loss: 0.3884\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3465 - val_loss: 0.3890\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.3452 - val_loss: 0.3815\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3423 - val_loss: 0.3815\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3414 - val_loss: 0.3762\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3390 - val_loss: 0.3833\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3372 - val_loss: 0.3775\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3343 - val_loss: 0.3768\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3328 - val_loss: 0.3729\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3314 - val_loss: 0.3731\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3299 - val_loss: 0.3758\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 725us/step - loss: 0.3293 - val_loss: 0.3740\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3267 - val_loss: 0.3677\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.3257 - val_loss: 0.3772\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3247 - val_loss: 0.3764\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3233 - val_loss: 0.3647\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3213 - val_loss: 0.3626\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.3204 - val_loss: 0.3607\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3186 - val_loss: 0.3661\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3190 - val_loss: 0.3626\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3177 - val_loss: 0.3576\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3156 - val_loss: 0.3574\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.3148 - val_loss: 0.3545\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3132 - val_loss: 0.3587\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3119 - val_loss: 0.3544\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3113 - val_loss: 0.3625\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3100 - val_loss: 0.3595\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3094 - val_loss: 0.3508\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3522\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3059 - val_loss: 0.3502\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3069 - val_loss: 0.3477\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.3052 - val_loss: 0.3507\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3046 - val_loss: 0.3497\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.3039 - val_loss: 0.3442\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.3015 - val_loss: 0.3447\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3016 - val_loss: 0.3472\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.3000 - val_loss: 0.3521\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3002 - val_loss: 0.3420\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.2994 - val_loss: 0.3452\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.2975 - val_loss: 0.3536\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.2954 - val_loss: 0.3603\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.2958 - val_loss: 0.3414\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.2953 - val_loss: 0.3427\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.2950 - val_loss: 0.3418\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.2932 - val_loss: 0.3379\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.2929 - val_loss: 0.3440\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.2923 - val_loss: 0.3424\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.2916 - val_loss: 0.3409\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2909 - val_loss: 0.3395\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.2907 - val_loss: 0.3382\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2901 - val_loss: 0.3353\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.2884 - val_loss: 0.3403\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.2885 - val_loss: 0.3492\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.2891 - val_loss: 0.3337\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.2878 - val_loss: 0.3348\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.2879 - val_loss: 0.3361\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.2866 - val_loss: 0.3352\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2849 - val_loss: 0.3407\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.2853 - val_loss: 0.3360\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.2840 - val_loss: 0.3346\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.2843 - val_loss: 0.3307\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.2821 - val_loss: 0.3347\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.2821 - val_loss: 0.3377\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2825 - val_loss: 0.3406\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.2811 - val_loss: 0.3428\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2828 - val_loss: 0.3372\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2803 - val_loss: 0.3351\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.2793 - val_loss: 0.3369\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.2796 - val_loss: 0.3318\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.2783 - val_loss: 0.3338\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.2790 - val_loss: 0.3377\n",
      "121/121 [==============================] - 0s 535us/step - loss: 0.3400\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0245 - val_loss: 0.5943\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.7809 - val_loss: 0.5704\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.5475 - val_loss: 0.5727\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5476 - val_loss: 0.5619\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.7178 - val_loss: 0.5634\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.7470 - val_loss: 0.5246\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.9632 - val_loss: 0.5137\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 2.2918 - val_loss: 0.5000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 2.7268 - val_loss: 0.6312\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 7.7546 - val_loss: 0.5070\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 180.2021 - val_loss: 0.7870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 12.1432 - val_loss: 1.1689\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 624us/step - loss: 814.1480 - val_loss: 1.8134\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 87.1091 - val_loss: 1.6451\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 73.2397 - val_loss: 2.7008\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 5103.8130 - val_loss: 196.8423\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 365.3940 - val_loss: 12.3616\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 22415.7422 - val_loss: 74.2818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 412us/step - loss: 2984.0078\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0850 - val_loss: 0.5906\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 4.7830 - val_loss: 0.9001\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 9.2729 - val_loss: 1.0581\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 24.5065 - val_loss: 4.5897\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 154.9895 - val_loss: 5.5882\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 26.8235 - val_loss: 0.6919\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 1016.8028 - val_loss: 14.4282\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 2785.6389 - val_loss: 18.9997\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 171.5966 - val_loss: 5.6251\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 15682.4473 - val_loss: 147.0859\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 44864.9062 - val_loss: 202.1367\n",
      "121/121 [==============================] - 0s 404us/step - loss: 756.9144\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 1.1061 - val_loss: 0.6196\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5669 - val_loss: 0.5529\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.5328 - val_loss: 0.5592\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5167 - val_loss: 0.5720\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.5168 - val_loss: 0.5573\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.5146 - val_loss: 0.5540\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5140 - val_loss: 0.5762\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 649us/step - loss: 0.5165 - val_loss: 0.5601\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.5144 - val_loss: 0.5619\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5136 - val_loss: 0.5889\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.5129 - val_loss: 0.5515\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.5141 - val_loss: 0.5684\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5154 - val_loss: 0.5544\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.5158 - val_loss: 0.5545\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5117 - val_loss: 0.5880\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.5172 - val_loss: 0.5603\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.5138 - val_loss: 0.5618\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 0.5148 - val_loss: 0.5572\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.5149 - val_loss: 0.6101\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.5149 - val_loss: 0.5665\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5145 - val_loss: 0.5702\n",
      "121/121 [==============================] - 0s 462us/step - loss: 0.5502\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2561 - val_loss: 1.0411\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.9236 - val_loss: 0.8332\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.8040 - val_loss: 0.7618\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 683us/step - loss: 0.7423 - val_loss: 0.7132\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.6962 - val_loss: 0.6721\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.6570 - val_loss: 0.6379\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.6224 - val_loss: 0.6081\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5914 - val_loss: 0.5813\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5656 - val_loss: 0.5603\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5446 - val_loss: 0.5437\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.5284 - val_loss: 0.5305\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5156 - val_loss: 0.5217\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.5054 - val_loss: 0.5141\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4972 - val_loss: 0.5104\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4904 - val_loss: 0.5054\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4847 - val_loss: 0.5003\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4796 - val_loss: 0.4998\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4755 - val_loss: 0.4946\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4717 - val_loss: 0.4912\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4686 - val_loss: 0.4881\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4656 - val_loss: 0.4845\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4802\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4602 - val_loss: 0.4782\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.4581 - val_loss: 0.4749\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.4559 - val_loss: 0.4754\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.4541 - val_loss: 0.4743\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4524 - val_loss: 0.4691\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4508 - val_loss: 0.4678\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.4491 - val_loss: 0.4635\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4477 - val_loss: 0.4641\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4462 - val_loss: 0.4601\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4449 - val_loss: 0.4618\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4432 - val_loss: 0.4622\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4423 - val_loss: 0.4595\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.4411 - val_loss: 0.4559\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4400 - val_loss: 0.4550\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4385 - val_loss: 0.4549\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4376 - val_loss: 0.4521\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4367 - val_loss: 0.4519\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.4357 - val_loss: 0.4503\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4346 - val_loss: 0.4484\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4336 - val_loss: 0.4479\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4329 - val_loss: 0.4475\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4322 - val_loss: 0.4464\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4313 - val_loss: 0.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4304 - val_loss: 0.4445\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4294 - val_loss: 0.4443\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4286 - val_loss: 0.4427\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4279 - val_loss: 0.4424\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4272 - val_loss: 0.4420\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4266 - val_loss: 0.4425\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4255 - val_loss: 0.4452\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4248 - val_loss: 0.4429\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4242 - val_loss: 0.4409\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4234 - val_loss: 0.4390\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.4229 - val_loss: 0.4368\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4223 - val_loss: 0.4364\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4213 - val_loss: 0.4372\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4207 - val_loss: 0.4356\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4199 - val_loss: 0.4388\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4194 - val_loss: 0.4340\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.4189 - val_loss: 0.4363\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4182 - val_loss: 0.4367\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4176 - val_loss: 0.4313\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4170 - val_loss: 0.4316\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 670us/step - loss: 0.4158 - val_loss: 0.4335\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4158 - val_loss: 0.4300\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.4152 - val_loss: 0.4293\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 679us/step - loss: 0.4142 - val_loss: 0.4307\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4141 - val_loss: 0.4281\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4135 - val_loss: 0.4287\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4125 - val_loss: 0.4319\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4125 - val_loss: 0.4286\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4119 - val_loss: 0.4296\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4113 - val_loss: 0.4280\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4106 - val_loss: 0.4282\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4102 - val_loss: 0.4253\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.4097 - val_loss: 0.4256\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4089 - val_loss: 0.4255\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4085 - val_loss: 0.4253\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4080 - val_loss: 0.4236\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4076 - val_loss: 0.4247\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4069 - val_loss: 0.4239\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4065 - val_loss: 0.4215\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.4059 - val_loss: 0.4231\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4053 - val_loss: 0.4220\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.4049 - val_loss: 0.4209\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.4042 - val_loss: 0.4203\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4040 - val_loss: 0.4210\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4030 - val_loss: 0.4228\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4026 - val_loss: 0.4190\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4021 - val_loss: 0.4192\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4019 - val_loss: 0.4186\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.4010 - val_loss: 0.4196\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4008 - val_loss: 0.4207\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4004 - val_loss: 0.4191\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4001 - val_loss: 0.4167\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3994 - val_loss: 0.4161\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3990 - val_loss: 0.4159\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.3985 - val_loss: 0.4153\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 453us/step - loss: 0.4100\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 7.0496WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7428 - val_loss: 1.5308\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 1.0859 - val_loss: 0.8109\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.7538 - val_loss: 0.7097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.6939 - val_loss: 0.6797\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.6666 - val_loss: 0.6626\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.6468 - val_loss: 0.6432\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.6297 - val_loss: 0.6275\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.6147 - val_loss: 0.6163\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.6012 - val_loss: 0.6079\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5895 - val_loss: 0.5947\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5786 - val_loss: 0.5837\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5686 - val_loss: 0.5796\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5593 - val_loss: 0.5678\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5513 - val_loss: 0.5618\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.5439 - val_loss: 0.5573\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.5371 - val_loss: 0.5502\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.5310 - val_loss: 0.5438\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 682us/step - loss: 0.5255 - val_loss: 0.5450\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 664us/step - loss: 0.5209 - val_loss: 0.5415\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5163 - val_loss: 0.5318\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.5120 - val_loss: 0.5284\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5081 - val_loss: 0.5273\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5045 - val_loss: 0.5232\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5013 - val_loss: 0.5231\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.4986 - val_loss: 0.5200\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 687us/step - loss: 0.4956 - val_loss: 0.5177\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4929 - val_loss: 0.5168\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.4906 - val_loss: 0.5163\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.5144\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4860 - val_loss: 0.5092\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4834 - val_loss: 0.5027\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4814 - val_loss: 0.4985\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4790 - val_loss: 0.5022\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4772 - val_loss: 0.4970\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4752 - val_loss: 0.4961\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.4733 - val_loss: 0.4942\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4714 - val_loss: 0.4894\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4693 - val_loss: 0.4871\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.4676 - val_loss: 0.4862\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4661 - val_loss: 0.4836\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4642 - val_loss: 0.4899\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4628 - val_loss: 0.4796\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4613 - val_loss: 0.4835\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4598 - val_loss: 0.4821\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 680us/step - loss: 0.4581 - val_loss: 0.4808\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4568 - val_loss: 0.4754\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4554 - val_loss: 0.4755\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4540 - val_loss: 0.4720\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4526 - val_loss: 0.4713\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4513 - val_loss: 0.4664\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4500 - val_loss: 0.4654\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4487 - val_loss: 0.4676\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4477 - val_loss: 0.4631\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4462 - val_loss: 0.4682\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 667us/step - loss: 0.4454 - val_loss: 0.4608\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4447 - val_loss: 0.4608\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4432 - val_loss: 0.4568\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.4426 - val_loss: 0.4608\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4411 - val_loss: 0.4601\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4408 - val_loss: 0.4567\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4396 - val_loss: 0.4560\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4388 - val_loss: 0.4541\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4379 - val_loss: 0.4529\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4370 - val_loss: 0.4537\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4362 - val_loss: 0.4540\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4355 - val_loss: 0.4535\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4346 - val_loss: 0.4556\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4339 - val_loss: 0.4573\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.4331 - val_loss: 0.4489\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 707us/step - loss: 0.4326 - val_loss: 0.4495\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 657us/step - loss: 0.4318 - val_loss: 0.4471\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 0.4310 - val_loss: 0.4476\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4306 - val_loss: 0.4476\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.4299 - val_loss: 0.4459\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.4293 - val_loss: 0.4431\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4289 - val_loss: 0.4444\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4280 - val_loss: 0.4419\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4275 - val_loss: 0.4459\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4271 - val_loss: 0.4414\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4262 - val_loss: 0.4415\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4256 - val_loss: 0.4389\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.4252 - val_loss: 0.4374\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.4247 - val_loss: 0.4389\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4241 - val_loss: 0.4362\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4236 - val_loss: 0.4362\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4226 - val_loss: 0.4433\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4227 - val_loss: 0.4362\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4220 - val_loss: 0.4348\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4218 - val_loss: 0.4366\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4210 - val_loss: 0.4385\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.4205 - val_loss: 0.4391\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 665us/step - loss: 0.4201 - val_loss: 0.4321\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4191 - val_loss: 0.4364\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 663us/step - loss: 0.4190 - val_loss: 0.4327\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4187 - val_loss: 0.4311\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4183 - val_loss: 0.4317\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4174 - val_loss: 0.4317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.4173 - val_loss: 0.4299\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4166 - val_loss: 0.4348\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.4163 - val_loss: 0.4301\n",
      "121/121 [==============================] - 0s 472us/step - loss: 0.3968\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6309 - val_loss: 0.9331\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.8469 - val_loss: 0.8036\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.7568 - val_loss: 0.7546\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.7095 - val_loss: 0.7170\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.6787 - val_loss: 0.6929\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.6557 - val_loss: 0.6722\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.6379 - val_loss: 0.6533\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.6227 - val_loss: 0.6428\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 719us/step - loss: 0.6093 - val_loss: 0.6262\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.5978 - val_loss: 0.6197\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.5871 - val_loss: 0.6070\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5774 - val_loss: 0.5964\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5686 - val_loss: 0.5906\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5605 - val_loss: 0.5804\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.5529 - val_loss: 0.5727\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.5459 - val_loss: 0.5649\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.5395 - val_loss: 0.5632\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5334 - val_loss: 0.5581\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.5280 - val_loss: 0.5499\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.5227 - val_loss: 0.5441\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5180 - val_loss: 0.5382\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.5137 - val_loss: 0.5355\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5095 - val_loss: 0.5328\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.5052 - val_loss: 0.5263\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.5018 - val_loss: 0.5236\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 638us/step - loss: 0.4981 - val_loss: 0.5220\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 691us/step - loss: 0.4948 - val_loss: 0.5245\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4916 - val_loss: 0.5172\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.4889 - val_loss: 0.5145\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.4859 - val_loss: 0.5127\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4829 - val_loss: 0.5113\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4806 - val_loss: 0.5076\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4776 - val_loss: 0.5031\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.4753 - val_loss: 0.4993\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4729 - val_loss: 0.5020\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4704 - val_loss: 0.5016\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.4683 - val_loss: 0.4951\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.4662 - val_loss: 0.4919\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4639 - val_loss: 0.4913\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4618 - val_loss: 0.4920\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4600 - val_loss: 0.4848\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4582 - val_loss: 0.4876\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4565 - val_loss: 0.4816\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4548 - val_loss: 0.4828\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4532 - val_loss: 0.4818\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.4515 - val_loss: 0.4771\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4500 - val_loss: 0.4771\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 700us/step - loss: 0.4478 - val_loss: 0.4759\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4469 - val_loss: 0.4743\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4457 - val_loss: 0.4726\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4443 - val_loss: 0.4730\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4428 - val_loss: 0.4715\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4729\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4405 - val_loss: 0.4670\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4398 - val_loss: 0.4683\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4384 - val_loss: 0.4698\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.4372 - val_loss: 0.4641\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4361 - val_loss: 0.4643\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4355 - val_loss: 0.4622\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 709us/step - loss: 0.4345 - val_loss: 0.4636\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4336 - val_loss: 0.4635\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.4328 - val_loss: 0.4606\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4320 - val_loss: 0.4616\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4308 - val_loss: 0.4588\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4302 - val_loss: 0.4617\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4294 - val_loss: 0.4585\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4287 - val_loss: 0.4607\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4278 - val_loss: 0.4609\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4268 - val_loss: 0.4635\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 658us/step - loss: 0.4267 - val_loss: 0.4615\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.4257 - val_loss: 0.4571\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.4250 - val_loss: 0.4558\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4244 - val_loss: 0.4548\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4239 - val_loss: 0.4545\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4232 - val_loss: 0.4546\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 610us/step - loss: 0.4227 - val_loss: 0.4518\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 692us/step - loss: 0.4221 - val_loss: 0.4551\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 711us/step - loss: 0.4216 - val_loss: 0.4526\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.4209 - val_loss: 0.4519\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.4204 - val_loss: 0.4515\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.4197 - val_loss: 0.4529\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4191 - val_loss: 0.4535\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4186 - val_loss: 0.4476\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4182 - val_loss: 0.4482\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 655us/step - loss: 0.4180 - val_loss: 0.4493\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4172 - val_loss: 0.4522\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.4166 - val_loss: 0.4483\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 642us/step - loss: 0.4162 - val_loss: 0.4466\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4157 - val_loss: 0.4490\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4150 - val_loss: 0.4479\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4147 - val_loss: 0.4461\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.4142 - val_loss: 0.4453\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4137 - val_loss: 0.4445\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4133 - val_loss: 0.4457\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.4130 - val_loss: 0.4474\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4124 - val_loss: 0.4463\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.4119 - val_loss: 0.4429\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 705us/step - loss: 0.4115 - val_loss: 0.4420\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 740us/step - loss: 0.4114 - val_loss: 0.4456\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.4107 - val_loss: 0.4434\n",
      "121/121 [==============================] - 0s 407us/step - loss: 0.4352\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001EDEE2583A0>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14148/1396660638.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3_64\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             self.best_estimator_ = clone(\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3_64\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m     96\u001b[0m                 \u001b[1;34m\"Cannot clone object %s, as the constructor \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;34m\"either does not set or modifies parameter %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001EDEE2583A0>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\": np.arange(1,100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras_API_gridsearch_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
